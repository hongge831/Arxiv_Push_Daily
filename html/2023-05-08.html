<h2>diffusion</h2>
<h3>标题: Controllable Light Diffusion for Portraits</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04745v1">http://arxiv.org/abs/2305.04745v1</a></li>
<li>主要机构: GoogleResearch</li>
<li>页数: 10</li>
<li>论文接收情况: CVPR 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种新的方法——光扩散，可以改善肖像照片的照明效果，软化强烈的阴影和高光，同时保持整体场景的照明。该方法受到专业摄影师扩散器和遮光布的启发，可以在仅有一张肖像照片的情况下软化照明。与以往的肖像重照方法不同，该方法可以控制光扩散的程度，并应用于野外肖像。此外，该研究还设计了一种方法，可以合成具有次表面散射效果的合理外部阴影，并符合主体脸部的形状。最后，该研究展示了该方法如何提高更高级别的视觉应用程序的鲁棒性，例如反照率估计、几何估计和语义分割。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04745v1] Controllable Light Diffusion for Portraits](http://arxiv.org/abs/2305.04745v1) #diffusion</code></li>
</ul>
<h3>标题: ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot Image Translation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04651v1">http://arxiv.org/abs/2305.04651v1</a></li>
<li>主要机构: ReGeneration Learning</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种基于ReGeneration学习的图像到图像扩散模型（ReDiffuser），它可以在不需要人工提示的情况下保留原始图像的内容，并自动在文本嵌入空间中发现所需的编辑方向。为了确保在图像编辑过程中形状的一致性保留，我们提出了基于交叉注意力引导的再生学习方法。此外，我们还引入了一种协作更新策略，可以有效地保留图像的原始形状，从而提高了形状保留的质量和一致性。实验结果表明，该方法在真实和合成图像编辑方面优于现有方法。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04651v1] ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot Image Translation](http://arxiv.org/abs/2305.04651v1) #diffusion</code></li>
</ul>
<h3>标题: Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04547v1">http://arxiv.org/abs/2305.04547v1</a></li>
<li>主要机构: None</li>
<li>页数: 21</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了Fine-purifying方法，利用扩散理论研究fine-tuning过程中的动态过程，以找到潜在的有毒维度并进行净化。通过检测不同维度的参数漂移和Hessian矩阵之间的关系，可以检测到异常动态的有毒维度，并将其重置为干净的预训练权重，然后在小型干净数据集上进行净化后的fine-tuning。实验结果验证了Fine-purifying方法的有效性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04547v1] Diffusion Theory as a Scalpel: Detecting and Purifying Poisonous Dimensions in Pre-trained Language Models Caused by Backdoor or Bias](http://arxiv.org/abs/2305.04547v1) #diffusion</code></li>
</ul>
<h3>标题: DiffBFR: Bootstrapping Diffusion Model Towards Blind Face Restoration</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04517v1">http://arxiv.org/abs/2305.04517v1</a></li>
<li>主要机构: University of Chinese Academy of Sciences</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: DiffBFR是一种盲面部恢复方法，采用扩散概率模型（DPM）来解决GAN方法的不稳定性和适应性问题。DiffBFR采用两步设计，首先从低质量图像中恢复身份信息，然后根据真实面部的分布增强纹理细节。其中，身份恢复模块（IRM）采用截断采样方法，以保留面部细节，而纹理增强模块（TEM）则采用无条件DPM来进一步强制恢复结果的真实性。通过理论证明，DiffBFR能够在保留身份信息的同时提高图像质量。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04517v1] DiffBFR: Bootstrapping Diffusion Model Towards Blind Face Restoration](http://arxiv.org/abs/2305.04517v1) #diffusion</code></li>
</ul>
<h3>标题: Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference!</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04465v1">http://arxiv.org/abs/2305.04465v1</a></li>
<li>主要机构: InstituteofComput.</li>
<li>页数: 26</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了两种简单而有效的方法，名为距离惩罚和自适应衰减采样，以解决扩散模型在训练和推理之间存在的差异。通过实验验证，这些方法可以在保持更好性能的同时，实现100倍到200倍的加速。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04465v1] Can Diffusion Model Achieve Better Performance in Text Generation? Bridging the Gap between Training and Inference!](http://arxiv.org/abs/2305.04465v1) #diffusion</code></li>
</ul>
<h3>标题: Locally Attentional SDF Diffusion for Controllable 3D Shape Generation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04461v2">http://arxiv.org/abs/2305.04461v2</a></li>
<li>主要机构: None</li>
<li>页数: 13</li>
<li>论文接收情况: SIGGRAPH 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种基于扩散的3D生成框架，名为局部关注SDF扩散，通过2D草图图像输入来建模可信的3D形状。该方法建立在两阶段扩散模型上，第一阶段旨在生成低分辨率的占据场，以近似形状外壳。第二阶段合成高分辨率的符号距离场，以提取精细几何形状。该模型通过一种新颖的视角感知局部注意机制来增强图像条件下的形状生成，从而提高了局部可控性和模型的普适性。通过大量实验，验证了该方法在草图条件和类别条件下生成可信和多样化的3D形状的能力，以及其对现有工作的优越可控性和普适性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04461v2] Locally Attentional SDF Diffusion for Controllable 3D Shape Generation](http://arxiv.org/abs/2305.04461v2) #diffusion</code></li>
</ul>
<h3>标题: Real-World Denoising via Diffusion Model</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04457v1">http://arxiv.org/abs/2305.04457v1</a></li>
<li>主要机构: Dalian University of Technology</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种新的通用扩散模型，可用于实际图像去噪。该模型采用线性插值的扩散过程，中间的噪声图像是从原始干净图像和相应的真实世界噪声图像插值得到的，因此可以处理添加噪声的级别。实验结果表明，该方法与简单的CNNs Unet相比，具有可比较的结果。在真实世界去噪基准测试中，定量和定性评估表明，所提出的通用扩散模型几乎可以与最先进的方法媲美。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04457v1] Real-World Denoising via Diffusion Model](http://arxiv.org/abs/2305.04457v1) #diffusion</code></li>
</ul>
<h3>标题: Prompt Tuning Inversion for Text-Driven Image Editing Using Diffusion Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04441v1">http://arxiv.org/abs/2305.04441v1</a></li>
<li>主要机构: BaiduVIS</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种基于Prompt Tuning Inversion的文本驱动图像编辑方法，通过重构阶段和编辑阶段实现。该方法可以在保持高保真度的同时，通过目标文本提示修改图像，例如改变特定物体的颜色而保留其原始形状和背景。在ImageNet上的实验表明，该方法的编辑性能优于现有基线方法。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04441v1] Prompt Tuning Inversion for Text-Driven Image Editing Using Diffusion Models](http://arxiv.org/abs/2305.04441v1) #diffusion</code></li>
</ul>
<h2>data-free</h2>
<h2>generative</h2>
<h3>标题: Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05061v1">http://arxiv.org/abs/2305.05061v1</a></li>
<li>主要机构: Coherent Wave Dynamics</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 大型语言模型（LLM）如生成预训练变压器（GPT）在各种语言任务中取得了巨大成功，但它们的新兴能力也引发了许多问题、关注和挑战，需要解决。为了更好地理解模型的内部机制，我们分析了小型GPT中的隐藏状态和通道波动动力学，重点关注波形的交叉通道相关性和个体自相关性的一致性。我们的发现表明，波动动力学提供了一致且可重复的内在振荡模式，以及语言生成中的上下文感知可塑性和表现力。通过分析波形、相干性和聚类，我们提供了一种系统的方法来识别和解释隐藏状态通道的功能，为理解和控制更高级别的语言模式形成铺平了道路。此外，我们调查了在各种模型训练水平下文本序列生成中拼写错误的泊松统计，并观察到类似于相变的过程。随着相干性的建立，正确和错误单词的生成之间存在竞争。然而，一旦模型训练得足够好并且显著的相干性已经出现，相干过程变得足够强大，可以有效地抑制拼写错误，防止缺陷的级联放大。正确拼写的分布从泊松分布转变为亚泊松分布，而错误拼写的分布则呈相反的趋势。通过利用量子物理的概念和技术，我们获得了对小型GPT动力学的新见解。这种方法可以扩展到展现更复杂相干语言模式的更大型语言模型，为解释它们的新兴能力和开发更专业的模型开辟了机会。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05061v1] Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer](http://arxiv.org/abs/2305.05061v1) #generative</code></li>
</ul>
<h3>标题: Learning to Evaluate the Artness of AI-generated Images</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04923v1">http://arxiv.org/abs/2305.04923v1</a></li>
<li>主要机构: University of Rochester</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 这篇论文提出了一种新的艺术评估指标ArtScore，用于评估人工智能生成的图像的艺术程度。该指标通过混合预训练的照片和艺术品生成模型，生成一系列具有不同艺术程度的图像，并用伪标注训练神经网络来评估任意图像的艺术程度。实验表明，ArtScore的评估结果更接近于人类的艺术评估。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04923v1] Learning to Evaluate the Artness of AI-generated Images](http://arxiv.org/abs/2305.04923v1) #generative</code></li>
</ul>
<h3>标题: How Do In-Context Examples Affect Compositional Generalization?</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04835v1">http://arxiv.org/abs/2305.04835v1</a></li>
<li>主要机构: Institute of Artificial Intelligence and Robotics</li>
<li>页数: 24</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一个名为CoFe的测试套件，用于研究上下文组合泛化。研究发现，上下文组合泛化性能很容易受到上下文示例的选择影响，因此提出了如何制作好的上下文示例以实现组合泛化的关键因素。研究了相似性、多样性和复杂性三个潜在因素，发现上下文示例应该在结构上与测试案例相似，彼此之间应该有所不同，并且单独简单。此外，还发现两个强限制：虚构词的上下文组合泛化比常用词要弱得多；即使骨干模型已经在大型语料库上进行了预训练，仍然很重要的是上下文示例应该涵盖所需的语言结构。希望这项研究能促进对上下文学习范式的理解和利用。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04835v1] How Do In-Context Examples Affect Compositional Generalization?](http://arxiv.org/abs/2305.04835v1) #generative</code></li>
</ul>
<h3>标题: HistAlign: Improving Context Dependency in Language Generation by Aligning with History</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04782v1">http://arxiv.org/abs/2305.04782v1</a></li>
<li>主要机构: UNCChapelHill</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种新的训练方法HistAlign，以确保缓存对齐，从而提高语言模型的上下文依赖性。该方法在多个语言生成任务中表现出色，包括提示延续、抽象摘要和数据到文本等。该方法还具有通用性，适用于不同的模型家族。研究代码公开可用。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04782v1] HistAlign: Improving Context Dependency in Language Generation by Aligning with History](http://arxiv.org/abs/2305.04782v1) #generative</code></li>
</ul>
<h3>标题: SkillQG: Learning to Generate Question for Reading Comprehension Assessment</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04737v1">http://arxiv.org/abs/2305.04737v1</a></li>
<li>主要机构: Zhejiang University</li>
<li>页数: 15</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种名为$\texttt{SkillQG}$的问题生成框架，可控制理解类型，用于评估和改进机器阅读理解模型。与现有的问题生成系统不同，$\texttt{SkillQG}$能够根据层次化的技能模式框架来定制问题的理解类型，从而更好地评估和改进问题回答模型。实验结果表明，$\texttt{SkillQG}$在质量、相关性和技能可控性方面优于基线模型，并在下游问题回答任务中表现出有希望的性能提升。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04737v1] SkillQG: Learning to Generate Question for Reading Comprehension Assessment](http://arxiv.org/abs/2305.04737v1) #generative</code></li>
</ul>
<h3>标题: Boosting Radiology Report Generation by Infusing Comparison Prior</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04561v1">http://arxiv.org/abs/2305.04561v1</a></li>
<li>主要机构: ETHZü</li>
<li>页数: 9</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 当前基于电流互感器的模型在从胸部X射线图像生成放射学报告方面取得了巨大成功。然而，其中一个主要问题是模型缺乏先前知识，这经常导致合成报告中对不存在的先前检查的虚假引用。为了解决这个问题，我们提出了一种新方法，利用标签器从IU X射线和MIMIC-CXR数据集的放射学报告中提取比较先前信息。然后将这个比较先前信息纳入最先进的基于变压器的模型中，使它们能够生成更真实和全面的报告。我们在IU X射线和MIMIC-CXR数据集上测试了我们的方法，并发现它在自动和人工评估指标方面优于以前的最先进模型。此外，与以前的模型不同，我们的模型生成的报告不包含对不存在的先前检查的虚假引用。我们的方法为弥合医学报告生成中放射科医生和生成模型之间的差距提供了一个有前途的方向。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04561v1] Boosting Radiology Report Generation by Infusing Comparison Prior](http://arxiv.org/abs/2305.04561v1) #generative</code></li>
</ul>
<h3>标题: Sparks of Artificial General Recommender (AGR): Early Experiments with ChatGPT</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04518v1">http://arxiv.org/abs/2305.04518v1</a></li>
<li>主要机构: Sparks of Artificial General Recommender (AGR)</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本研究探讨了利用最新的大型语言模型（LLMs）开发人工智能通用推荐系统（AGR）的可行性。AGR具有对话性和普适性，可以在各个领域进行自然对话和生成推荐。我们提出了十个基本原则，每个原则都有相应的测试协议。我们通过与ChatGPT进行推荐导向的对话并观察其行为来评估ChatGPT是否能够遵守所提出的原则。我们的研究结果表明，ChatGPT有潜力成为AGR，但也发现了一些限制和改进的空间。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04518v1] Sparks of Artificial General Recommender (AGR): Early Experiments with ChatGPT](http://arxiv.org/abs/2305.04518v1) #generative</code></li>
</ul>
<h3>标题: MGR: Multi-generator based Rationalization</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04492v1">http://arxiv.org/abs/2305.04492v1</a></li>
<li>主要机构: Huazhong University of Science and Technology</li>
<li>页数: 14</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种名为MGR的简单而有效的方法，旨在同时解决理性化中的两个挑战：虚假相关性和退化。该方法采用多个生成器，以提高真实片段的出现稳定性并向预测器提供更有意义的片段。实验证明，MGR相对于现有技术提高了F1得分高达20.9％。代码可在https://github.com/jugechengzi/Rationalization-MGR上获得。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04492v1] MGR: Multi-generator based Rationalization](http://arxiv.org/abs/2305.04492v1) #generative</code></li>
</ul>
<h3>标题: Generalized Universal Domain Adaptation with Generative Flow Networks</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04466v1">http://arxiv.org/abs/2305.04466v1</a></li>
<li>主要机构: Zhejiang University</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种新的无监督领域自适应问题，称为广义通用领域自适应（GUDA），旨在实现对所有目标标签的精确预测，包括未知类别。GUDA将基于标签分布偏移和标签空间不匹配的变体联系起来，将它们归类为一个统一的问题，为彻底解决所有变体提供了全面的框架。GUDA的关键挑战是在估计目标标签分布的同时开发和识别新的目标类别。为了解决这个问题，我们利用生成流网络的强大探索能力，提出了一种名为GFlowDA的主动领域自适应算法，该算法选择多样化的样本，其概率与奖励函数成比例。为了增强探索能力并有效地感知目标标签分布，我们定制了状态和奖励，并引入了一种有效的父探索和状态转换解决方案。我们还提出了一种名为广义通用对抗网络（GUAN）的GUDA训练范式，其中涉及GUAN和GFlowNet之间的协作优化。理论分析强调了探索的重要性，对基准数据集的广泛实验表明了GFlowDA的优越性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04466v1] Generalized Universal Domain Adaptation with Generative Flow Networks](http://arxiv.org/abs/2305.04466v1) #generative</code></li>
</ul>
<h3>标题: Improving Cross-Task Generalization with Step-by-Step Instructions</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04429v1">http://arxiv.org/abs/2305.04429v1</a></li>
<li>主要机构: Harbin Institute of Technology</li>
<li>页数: 15</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种将逐步指导步骤与原始指导结合起来，以帮助语言模型分解任务的方法，从而提高跨任务泛化能力。通过ChatGPT自动获取逐步指导步骤，并与原始指导结合，进行语言模型调整。实验结果表明，高质量的逐步指导步骤可以提高不同模型大小的跨任务泛化能力。此外，进一步分析表明，逐步指导步骤的顺序对改进至关重要。为了促进未来的研究，我们发布了逐步指导步骤及其人工质量评估结果。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04429v1] Improving Cross-Task Generalization with Step-by-Step Instructions](http://arxiv.org/abs/2305.04429v1) #generative</code></li>
</ul>
<h2>language model</h2>
<h3>标题: Accessible Instruction-Following Agent</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06358v1">http://arxiv.org/abs/2305.06358v1</a></li>
<li>主要机构: None</li>
<li>页数: 27</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了一种新的机器翻译指令增强框架，名为UVLN（通用视觉语言导航），旨在将指令跟随代理推广到非英语语言，并提高其可操作性和可访问性。该框架采用了最先进的大型语言模型（GPT3）和图像字幕模型（BLIP），通过跨语言语言编码器将标准VLN训练目标扩展到多语言环境中。通过跨模态变压器，对不同语言之间的对齐进行捕捉，以编码语言指令、视觉观察和行动决策序列的输入。为了提高可操作性，我们将代理与大型语言模型连接起来，向用户提供情境和当前状态的信息，并解释行动决策。实验结果表明，我们的方法在Room Across Room数据集上取得了良好的效果，并显示出指令跟随代理的良好可操作性和可访问性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06358v1] Accessible Instruction-Following Agent](http://arxiv.org/abs/2305.06358v1) #language model</code></li>
</ul>
<h3>标题: Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05095v1">http://arxiv.org/abs/2305.05095v1</a></li>
<li>主要机构: AppleAI/ML</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文讨论了两种有效的方法来提高CLIP模型的效率和鲁棒性：（1）增加训练数据集，同时保持相同数量的优化步骤，（2）过滤包含图像文本区域的样本。通过这样做，我们显着提高了在ImageNet和CoCo等公共基准测试中的分类和检索准确性。过滤带有文本区域的图像还可以保护模型免受印刷攻击。我们构建了一个名为ImageNet with Adversarial Text Regions（ImageNet-Attr）的新数据集来验证这一点。我们的基于过滤的CLIP模型表现出68.78％的top-1准确率，优于以前准确率都低于50％的模型。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05095v1] Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness](http://arxiv.org/abs/2305.05095v1) #language model</code></li>
</ul>
<h3>标题: Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05094v1">http://arxiv.org/abs/2305.05094v1</a></li>
<li>主要机构: Microsoft Research</li>
<li>页数: 20</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种交互式框架，旨在帮助专家更好地理解大型文本集合。该框架将主题的定义扩展到不仅仅是单词分布，还包括领域专家认为相关的广义概念。同时，该框架兼顾自动化和手动编码，使专家能够掌控研究同时减少手动工作量。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05094v1] Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections](http://arxiv.org/abs/2305.05094v1) #language model</code></li>
</ul>
<h3>标题: Knowledge-enhanced Agents for Interactive Text Games</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05091v1">http://arxiv.org/abs/2305.05091v1</a></li>
<li>主要机构: University of Southern California</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一个框架，旨在提高基于文本游戏中代理的功能基础。该框架支持三种代理模型，包括纯强化学习代理、增强了知识图谱的强化学习代理和配备语言模型的代理。我们在ScienceWorld文本游戏环境中进行了所有实验，以展示各种模型配置在具有挑战性的科学相关指令遵循任务中的性能。我们的发现为开发交互式上下文中有效的自然语言处理系统提供了重要见解。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05091v1] Knowledge-enhanced Agents for Interactive Text Games](http://arxiv.org/abs/2305.05091v1) #language model</code></li>
</ul>
<h3>标题: Multi-Task End-to-End Training Improves Conversational Recommendation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06218v1">http://arxiv.org/abs/2305.06218v1</a></li>
<li>主要机构: GoogleResearch</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文分析了一种多任务端到端变压器模型在对话推荐任务上的表现，该任务旨在根据用户在对话中明确表达的偏好提供推荐。我们展示了一个基于T5文本到文本变压器模型的统一变压器模型可以在推荐相关项目和生成对话方面具有竞争力，而以前在这个领域的工作采用了复杂的多组件方法，其中对话管理和实体推荐任务由单独的组件处理。我们在ReDIAL对话电影推荐数据集上对我们的模型进行微调，并在多任务学习设置中创建了从MovieLens派生的额外训练任务（例如基于输入电影预测电影属性和相关电影），使用一系列探针研究，我们证明了额外任务中学习的知识被转移到了对话设置中，其中每个任务导致其相关探针分数增加了9％-52％。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06218v1] Multi-Task End-to-End Training Improves Conversational Recommendation](http://arxiv.org/abs/2305.06218v1) #language model</code></li>
</ul>
<h3>标题: A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05079v1">http://arxiv.org/abs/2305.05079v1</a></li>
<li>主要机构: None</li>
<li>页数: 23</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 自然语言处理模型在“封闭世界”环境下表现出色，但在现实世界中，经常会出现不属于任何已知类别的“新颖”实例，因此处理新颖性的能力至关重要。为了系统研究这一重要领域，研究人员引入了“NoveltyTask”，这是一个多阶段任务，用于评估系统在管道式新颖性“检测”和“适应”任务上的表现。研究人员使用亚马逊评论语料库编译了一个大型数据集，用于NoveltyTask的作者归属任务。他们进行了全面的实验，并探索了几种基线方法。结果表明，这些方法的表现相当低，使任务具有挑战性，并留下了足够的改进空间。最后，研究人员相信他们的工作将鼓励在处理新颖性这一未被充分探索的领域进行研究，这是开发强大系统的重要一步。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05079v1] A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution](http://arxiv.org/abs/2305.05079v1) #language model</code></li>
</ul>
<h3>标题: Indoor Localization and Multi-person Tracking Using Privacy Preserving Distributed Camera Network with Edge Computing</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05062v1">http://arxiv.org/abs/2305.05062v1</a></li>
<li>主要机构: IndoorLocalizationandMulti-personTrackingUsingPrivacyPreserving</li>
<li>页数: 29</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了一种开源、低成本、可扩展且保护隐私的边缘计算框架，用于多人定位，即在室内空间中估计多个人的位置、方向和轨迹。该框架由38个Tensor Processing Unit（TPU）启用的边缘计算摄像系统组成，安装在室内治疗空间的天花板上。边缘计算系统通过安全和私密的网络连接到本地雾服务器。我们实现了基于卡尔曼滤波的多人跟踪方法和最先进的身体方向估计方法，以确定室内多人的位置和面向方向。在我们的研究场地，该系统表现出平均定位误差为1.41米，多对象跟踪准确度得分为62％，平均绝对身体方向误差为29度。此外，我们的研究通过分析相机安装的各个元素，为部署所提出的系统提供了实用的指导。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05062v1] Indoor Localization and Multi-person Tracking Using Privacy Preserving Distributed Camera Network with Edge Computing](http://arxiv.org/abs/2305.05062v1) #language model</code></li>
</ul>
<h3>标题: Crack Detection of Asphalt Concrete Using Combined Fracture Mechanics and Digital Image Correlation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05057v1">http://arxiv.org/abs/2305.05057v1</a></li>
<li>主要机构: Univ.</li>
<li>页数: 24</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种使用二维数字图像相关（DIC）检测AC试件表面裂缝的框架。该方法解决了以往研究中的两个主要问题，即大变形和不连续性导致的装饰问题以及基于位移场的裂缝检测方法。该框架可以应用于表征AC开裂现象，评估其断裂性能，评估沥青混合物测试协议和开发理论模型。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05057v1] Crack Detection of Asphalt Concrete Using Combined Fracture Mechanics and Digital Image Correlation](http://arxiv.org/abs/2305.05057v1) #language model</code></li>
</ul>
<h3>标题: Dreams Are More "Predictable'' Than You Think</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05054v1">http://arxiv.org/abs/2305.05054v1</a></li>
<li>主要机构: University of Sussex</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 研究表明，与其他文本记录相比，梦境报告在语义内容方面存在显着差异。然而，梦境/睡眠研究界普遍认为，梦境报告构成了相当“独特”的文本字符串。这可能对使用自然语言处理工具自动分析梦境报告的方法构成重要问题。本研究采用最先进的大型语言模型，研究梦境报告是否以及如何偏离其他人类生成的文本字符串，如维基百科。结果显示，DreamBank整体上与维基百科没有偏差。此外，单个梦境报告平均比维基百科文章更可预测。初步证据表明，字数、性别和视力障碍可能会显着影响梦境报告对模型的可预测性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05054v1] Dreams Are More "Predictable'' Than You Think](http://arxiv.org/abs/2305.05054v1) #language model</code></li>
</ul>
<h3>标题: ANALOGICAL -- A New Benchmark for Analogy of Long Text for Large Language Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05050v1">http://arxiv.org/abs/2305.05050v1</a></li>
<li>主要机构: ANALOGICAL</li>
<li>页数: 14</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一个名为ANALOGICAL的新基准，用于评估大型语言模型（LLMs）在长文本的类比方面的能力。该基准包括六个复杂级别的类比，使用13个数据集和三种不同的距离度量来评估8个LLMs的能力。研究发现，随着类比层次的提高，LLMs越来越难以识别类比。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05050v1] ANALOGICAL -- A New Benchmark for Analogy of Long Text for Large Language Models](http://arxiv.org/abs/2305.05050v1) #language model</code></li>
</ul>
<h3>标题: Web Content Filtering through knowledge distillation of Large Language Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05027v2">http://arxiv.org/abs/2305.05027v2</a></li>
<li>主要机构: SophosInc.</li>
<li>页数: 17</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种基于大型语言模型的URL分类方法，旨在通过限制访问高风险或可疑网站，保护组织免受法律和道德风险，并促进安全和专业的工作环境。该方法利用LLMs生成准确的分类，然后采用知识蒸馏技术创建更小、更专业的学生模型，以进行Web内容过滤。该学生模型在分类网站方面的准确率提高了9%，超过了当前最先进的方法。该学生模型与教师LLM的性能相匹配，参数少了175倍，需要的手动标记训练数据比当前最先进的方法少了3个数量级。根据具体用例，该方法生成的输出可以直接返回或用作更耗费资源的涉及网站图像或HTML的操作的预过滤器。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05027v2] Web Content Filtering through knowledge distillation of Large Language Models](http://arxiv.org/abs/2305.05027v2) #language model</code></li>
</ul>
<h3>标题: Self-supervised Pre-training with Masked Shape Prediction for 3D Scene Understanding</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05026v1">http://arxiv.org/abs/2305.05026v1</a></li>
<li>主要机构: Max Planck Institute for Informatics</li>
<li>页数: 11</li>
<li>论文接收情况: CVPR 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了一种新的框架——Masked Shape Prediction（MSP），用于在三维场景中进行掩码信号建模。MSP使用基本的三维语义线索——几何形状作为掩码点的预测目标。同时，MSP的预训练架构经过精心设计，以减轻掩码形状泄漏的问题。实验表明，MSP在学习良好的特征表示方面非常有效，可以持续提高下游性能。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05026v1] Self-supervised Pre-training with Masked Shape Prediction for 3D Scene Understanding](http://arxiv.org/abs/2305.05026v1) #language model</code></li>
</ul>
<h3>标题: Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05023v2">http://arxiv.org/abs/2305.05023v2</a></li>
<li>主要机构: None</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种新的图像到图像翻译方法，旨在将源图像的视觉特征与低分辨率目标图像的低频信息相结合，生成高质量的图像。该方法在CelebA-HQ和AFHQ数据集上进行了验证，结果表明相比于StarGAN v2等现有方法，该方法在视觉质量方面有所提高，并且具有颜色稳健性、适用于分布外图像和手动控制等优点。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05023v2] Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning](http://arxiv.org/abs/2305.05023v2) #language model</code></li>
</ul>
<h3>标题: Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge Distillation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05010v1">http://arxiv.org/abs/2305.05010v1</a></li>
<li>主要机构: Georgia Institute of Technology</li>
<li>页数: 16</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 知识蒸馏是一种将大型教师模型的知识转移给小型学生模型的流行技术。本文认为，通常情况下，学生通过最小化其输出分布与教师输出分布之间的KL散度来模仿教师是次优的，因为教师的输出分布与真实标签分布之间存在差异。因此，强制学生盲目模仿不可靠的教师输出分布会导致性能下降。为此，本文提出了一种新的知识蒸馏目标PTLoss，通过首先通过Maclaurin级数表示香草KL基础蒸馏损失函数，然后扰动该级数中的主导项来实现。这种扰动的损失隐含地将原始教师转化为一个更接近真实分布的代理教师。我们建立了这种“分布接近性”与学生模型的普适性之间的理论联系，这使我们能够以原则的方式选择PTLoss的扰动系数。在五个数据集上的广泛实验表明，PTLoss可以显著提高各种规模的教师的蒸馏效果。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05010v1] Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge Distillation](http://arxiv.org/abs/2305.05010v1) #language model</code></li>
</ul>
<h3>标题: ComputeGPT: A computational chat model for numerical problems</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06223v1">http://arxiv.org/abs/2305.06223v1</a></li>
<li>主要机构: The University of Texas at Austin</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该论文介绍了ComputeGPT，一种创建聊天模型的方法，能够通过运行按需代码来回答计算问题。ComputeGPT将每个问题转换为相关代码，运行代码，并将计算出的答案作为聊天的一部分返回。该方法结合了本地基于浏览器的Python解释器和精细调整的提示，以实现在数字问题上的最先进效率，并为代码提供适当的前端和安全环境。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06223v1] ComputeGPT: A computational chat model for numerical problems](http://arxiv.org/abs/2305.06223v1) #language model</code></li>
</ul>
<h3>标题: Revisiting Relation Extraction in the era of Large Language Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05003v1">http://arxiv.org/abs/2305.05003v1</a></li>
<li>主要机构: NortheasternUniversity</li>
<li>页数: 22</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 关系抽取是从文本中推断实体之间语义关系的核心自然语言处理任务。最近的研究将该问题视为序列到序列任务，将实体之间的关系线性化为目标字符串，以输入为条件生成。本研究使用比以前更大的语言模型（GPT-3和Flan-T5 large），在不同程度的监督下评估它们在标准关系抽取任务中的表现。通过人工评估，我们发现：（1）使用GPT-3进行少量提示可以实现接近SOTA的性能，即与现有完全监督模型大致相当；（2）Flan-T5在少量提示的情况下不太能胜任，但通过Chain-of-Thought（CoT）样式的解释进行监督和微调（由GPT-3生成）可以获得SOTA结果。我们将这个模型发布为关系抽取任务的新基准。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05003v1] Revisiting Relation Extraction in the era of Large Language Models](http://arxiv.org/abs/2305.05003v1) #language model</code></li>
</ul>
<h3>标题: GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05001v1">http://arxiv.org/abs/2305.05001v1</a></li>
<li>主要机构: GersteinLab</li>
<li>页数: 9</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了我们在MEDIQA-2023 Dialogue2Note共享任务中的贡献，包括子任务A和子任务B。我们将任务视为对话摘要问题，并实现了两个不同的流程：（a）对预训练的对话摘要模型和GPT-3进行微调，（b）使用大型语言模型GPT-4进行少量上下文学习（ICL）。两种方法在ROUGE-1 F1、BERTScore F1（deberta-xlarge-mnli）和BLEURT方面均取得了出色的成绩，分别为0.4011、0.7058和0.5421。此外，我们使用RoBERTa和SciBERT基于分类模型预测相关的章节标题。我们的团队在所有团队中排名第四，每个团队可以提交三次运行作为其提交的一部分。我们还利用专家注释证明，通过ICL GPT-4生成的笔记比所有其他基线更好。我们的提交代码可用。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05001v1] GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning](http://arxiv.org/abs/2305.05001v1) #language model</code></li>
</ul>
<h3>标题: Crop identification using deep learning on LUCAS crop cover photos</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04994v1">http://arxiv.org/abs/2305.04994v1</a></li>
<li>主要机构: EuropeanCommis.</li>
<li>页数: 16</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文旨在选择和发布欧盟12种成熟主要作物的LUCAS覆盖照片子集，以部署、基准测试和确定Mobile-net的最佳配置，展示使用基于熵的指标进行后处理结果的可能性，以及在实际和政策相关背景下展示模型的应用和局限性。该工作已经产生了169,460张成熟作物的图像数据集，其中15,876张被手动选择为不含任何异物或不利条件的干净样本。最佳表现模型在8,642张测试数据集上实现了0.75的宏F1（M-F1）。使用信息理论的度量标准，即等价参考概率，结果实现了6%的增长。该方法表明，可以使用最少的辅助数据，在12个主要欧洲作物之间实现0.817的标记M-F1。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04994v1] Crop identification using deep learning on LUCAS crop cover photos](http://arxiv.org/abs/2305.04994v1) #language model</code></li>
</ul>
<h3>标题: Explanation-based Finetuning Makes Models More Robust to Spurious Cues</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04990v1">http://arxiv.org/abs/2305.04990v1</a></li>
<li>主要机构: University of Pennsylvania</li>
<li>页数: 17</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 大型语言模型（LLMs）有时会学习与任务无关的标签和特征之间的相关性，导致在分布外数据上的泛化能力较差。为了缓解LLMs对虚假相关性的依赖，我们提出了基于解释的微调作为一种新的通用方法。与标准微调只预测给定输入的答案不同，我们微调模型以生成支持其答案的自由文本解释。通过在人工构建的训练集上微调模型，并在没有这些提示的测试集上进行测试，我们评估了我们的方法。与标准微调相比，我们的方法在四个分类任务（ComVE（+1.2），CREAK（+9.1），e-SNLI（+15.4）和SBIC（+6.5））中使模型对虚假提示的准确性下降更加鲁棒。此外，我们的方法同样适用于模型生成的解释，这意味着它适用于更多没有人工编写解释的数据集。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04990v1] Explanation-based Finetuning Makes Models More Robust to Spurious Cues](http://arxiv.org/abs/2305.04990v1) #language model</code></li>
</ul>
<h3>标题: NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04978v1">http://arxiv.org/abs/2305.04978v1</a></li>
<li>主要机构: NeuroComparatives</li>
<li>页数: 14</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文研究了比较知识获取的任务，提出了一种新的框架NeuroComparatives，使用词汇约束解码和严格过滤生成的知识，获得了比较日常物品的知识，结果比现有资源大10倍，多样性增加了30％。人类评估表明，NeuroComparatives优于现有资源（绝对改进高达32％），即使使用100倍较小的模型也优于GPT-3。这些结果表明，使用较小的模型进行神经符号操作是一种成本效益的替代方案，而不是依赖于具有有限推理访问权限的极端规模语言模型的主流做法。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04978v1] NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge](http://arxiv.org/abs/2305.04978v1) #language model</code></li>
</ul>
<h3>标题: LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04971v1">http://arxiv.org/abs/2305.04971v1</a></li>
<li>主要机构: Huawei Noah's Ark Lab</li>
<li>页数: 15</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 正则化技术对于提高深度神经网络的泛化性能和训练效率至关重要。标签平滑是一种简单、多功能和高效的正则化方法，可以应用于各种监督分类任务。本文提出了一种通用的标签正则化训练框架，包括传统的标签平滑，但也可以建模特定实例的变体。基于这个公式，我们提出了一种有效的学习标签正则化的方法，通过设计一个双层优化问题来推导内部循环的确定性和可解释的解决方案，无需存储训练模型的参数或输出。最后，我们进行了广泛的实验，并证明我们的方法在各个领域，包括七个机器翻译和三个图像分类任务中，始终优于传统的标签正则化。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04971v1] LABO: Towards Learning Optimal Label Regularization via Bi-level Optimization](http://arxiv.org/abs/2305.04971v1) #language model</code></li>
</ul>
<h3>标题: Joint Moment Retrieval and Highlight Detection Via Natural Language Queries</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04961v1">http://arxiv.org/abs/2305.04961v1</a></li>
<li>主要机构: GeorgiaIns.</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该项目提出了一种新的自然语言查询基于多模态变压器的联合视频摘要和亮点检测方法。该方法使用视觉和音频线索来匹配用户的自然语言查询，以检索视频中最相关和有趣的时刻。该方法采用了多种最近在Vision Transformers (ViTs)中使用的技术，创建了一个类似于编码器-解码器模型的变压器。作者在多个数据集上进行了评估，如YouTube Highlights和TVSum，以展示所提出方法的灵活性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04961v1] Joint Moment Retrieval and Highlight Detection Via Natural Language Queries](http://arxiv.org/abs/2305.04961v1) #language model</code></li>
</ul>
<h3>标题: PillarNeXt: Rethinking Network Designs for 3D Object Detection in LiDAR Point Clouds</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04925v1">http://arxiv.org/abs/2305.04925v1</a></li>
<li>主要机构: PillarNeXt</li>
<li>页数: 11</li>
<li>论文接收情况: CVPR 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文重新审视了局部点聚合器的计算资源分配问题，发现最简单的基于柱状体的模型在准确性和延迟方面表现出色。同时，通过借鉴2D目标检测的成功经验，如扩大感受野等，可以显著提高性能。实验结果表明，我们基于柱状体的网络在架构和训练方面的现代化设计，可以在Waymo Open Dataset和nuScenes等两个流行基准测试中实现最先进的性能，挑战了详细几何建模对于实现高性能3D目标检测的普遍直觉。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04925v1] PillarNeXt: Rethinking Network Designs for 3D Object Detection in LiDAR Point Clouds](http://arxiv.org/abs/2305.04925v1) #language model</code></li>
</ul>
<h3>标题: What Do Patients Say About Their Disease Symptoms? Deep Multilabel Text Classification With Human-in-the-Loop Curation for Automatic Labeling of Patient Self Reports of Problems</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04905v1">http://arxiv.org/abs/2305.04905v1</a></li>
<li>主要机构: None</li>
<li>页数: 8</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文探讨了一个包含170,141个自我报告的开放式回答（称为“文本”）的在线数据集，这些回答来自帕金森病患者，涉及他们对帕金森病的困扰以及如何影响他们的日常生活。将这些文本分类为多个临床相关的症状类别是一个重要的问题，需要多个步骤 - 专家策划，多标签文本分类（MLTC）方法和大量标记的训练数据。我们提出了一种新的解决方案，其中我们使用2,341个文本构建了一个基线数据集，使用NLP技术和基于图形数据库的专家短语查询系统开发了基于规则的语言字典，以扩展注释到其余队列生成机器注释数据集，并最终为两个数据集构建了基于Keras-Tensorflow的MLTC模型。机器注释模型在65个症状类别上的F1分数为95％，显著优于基线模型。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04905v1] What Do Patients Say About Their Disease Symptoms? Deep Multilabel Text Classification With Human-in-the-Loop Curation for Automatic Labeling of Patient Self Reports of Problems](http://arxiv.org/abs/2305.04905v1) #language model</code></li>
</ul>
<h3>标题: SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04868v1">http://arxiv.org/abs/2305.04868v1</a></li>
<li>主要机构: IEEE</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了第一个自我监督预训练的SignBERT+框架，其中包含模型感知的手部先验知识。该框架将手势姿势视为视觉令牌，并使用手势状态和空间-时间位置编码进行嵌入。通过自我监督学习来模拟常见的失败检测情况，并结合模型感知的手部先验知识来更好地捕捉序列中的分层上下文。在预训练后，设计了简单而有效的预测头用于下游任务。实验结果表明，该方法在隔离和连续手语识别以及手语翻译方面取得了新的最佳表现。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04868v1] SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding](http://arxiv.org/abs/2305.04868v1) #language model</code></li>
</ul>
<h3>标题: A Frustratingly Easy Improvement for Position Embeddings via Random Padding</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04859v1">http://arxiv.org/abs/2305.04859v1</a></li>
<li>主要机构: Wangxuan Institute of Computer Technology</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种名为“随机填充”的策略，用于解决在提取式问答中，由于位置嵌入的更新次数不均衡，导致后面的位置嵌入训练不足的问题。该策略通过调整输入序列的顺序，平衡每个位置嵌入的更新次数，从而显著提高了模型在答案位于后面位置的实例上的性能，特别是在短上下文训练但长上下文评估的情况下。该策略不需要对现有预训练语言模型的架构进行任何修改。作者将发布代码和数据以供未来研究使用。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04859v1] A Frustratingly Easy Improvement for Position Embeddings via Random Padding](http://arxiv.org/abs/2305.04859v1) #language model</code></li>
</ul>
<h3>标题: The Current State of Summarization</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04853v1">http://arxiv.org/abs/2305.04853v1</a></li>
<li>主要机构: Karlsruhe Institute of Technology (KIT)</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文旨在简要介绍抽象文本摘要的最新技术现状，包括预训练编码器-解码器模型和大型自回归语言模型的范式转变。同时，我们探讨了评估摘要系统的挑战以及零-shot摘要的指导调整模型的潜力。最后，我们简要概述了摘要系统如何被整合到商业应用中。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04853v1] The Current State of Summarization](http://arxiv.org/abs/2305.04853v1) #language model</code></li>
</ul>
<h3>标题: The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04940v1">http://arxiv.org/abs/2305.04940v1</a></li>
<li>主要机构: Simula</li>
<li>页数: 12</li>
<li>论文接收情况: FSE 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文探讨了如何在训练深度自然语言处理模型时最大化利用资源和可用信息。作者提出了一种通用方法EarlyBIRD，通过使用预训练变压器模型的早期层来构建代码的复合表示。在CodeBERT模型上进行的实证研究表明，使用早期层组合可以在缩小资源使用的同时获得更好的结果。在四个数据集上的评估表明，使用早期层组合可以在缺陷检测和多类分类方面获得更好的性能。作者在Devign数据集上获得了+2的平均检测准确度提高，同时在微调中获得了3.3倍的加速。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04940v1] The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification](http://arxiv.org/abs/2305.04940v1) #language model</code></li>
</ul>
<h3>标题: Reinforcement Learning for Topic Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04843v1">http://arxiv.org/abs/2305.04843v1</a></li>
<li>主要机构: University of Alberta</li>
<li>页数: 18</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文将强化学习技术应用于主题建模，通过用连续动作空间强化学习策略替换ProdLDA中的变分自编码器。使用REINFORCE策略梯度算法进行训练，并进行了多项修改，包括现代化的神经网络架构、加权ELBO损失、使用上下文嵌入和监控学习过程。在11个数据集上进行实验，结果表明我们的无监督模型优于所有其他无监督模型，并与大多数使用监督标签的模型表现相当或更好。我们的模型在某些数据集上被使用监督标签和对比学习的模型超越。我们还进行了消融研究，提供了对ProdLDA进行改进的实证证据，并发现强化学习公式提高了性能。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04843v1] Reinforcement Learning for Topic Models](http://arxiv.org/abs/2305.04843v1) #language model</code></li>
</ul>
<h3>标题: Learning Summary-Worthy Visual Representation for Abstractive Summarization in Video</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04824v1">http://arxiv.org/abs/2305.04824v1</a></li>
<li>主要机构: School of Computer Science</li>
<li>页数: 9</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种新的多模态抽象视频摘要方法，通过将视觉信息与文本信息相结合，生成简洁的文本摘要。该方法利用了跨模态文本数据和伪摘要中提取的知识，学习了值得总结的视觉表示，从而提高了模型性能。实验结果表明，该方法在三个公共多模态数据集上的表现优于其他基线模型，特别是在小数据集或有限训练数据集上表现更加突出。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04824v1] Learning Summary-Worthy Visual Representation for Abstractive Summarization in Video](http://arxiv.org/abs/2305.04824v1) #language model</code></li>
</ul>
<h3>标题: A Drop of Ink may Make a Million Think: The Spread of False Information in Large Language Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04812v1">http://arxiv.org/abs/2305.04812v1</a></li>
<li>主要机构: School of Computer Science and Tech.</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文研究了虚假信息在大型语言模型（LLMs）中的传播和影响机制，通过实验比较了信息来源权威性、注入范式和信息相关性对LLMs的影响。结果表明，虚假信息会通过语义扩散过程在LLMs中传播和污染相关记忆，当前LLMs容易受到权威偏见的影响，更容易跟随新闻或研究论文等可信的虚假信息，而且在上下文注入中更容易受到虚假信息的影响。因此，需要新的虚假信息防御算法和新的对齐算法来引导LLMs遵循内在的人类价值观。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04812v1] A Drop of Ink may Make a Million Think: The Spread of False Information in Large Language Models](http://arxiv.org/abs/2305.04812v1) #language model</code></li>
</ul>
<h3>标题: CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04808v2">http://arxiv.org/abs/2305.04808v2</a></li>
<li>主要机构: Department of Computer Science</li>
<li>页数: 28</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: CAT是一个半监督学习框架，旨在填补常识建模的研究空白。它集成了事件概念化和实例化，以在规模上概念化常识知识库。实验表明，该框架在两个概念化任务上实现了最先进的性能，并且获得的抽象常识知识可以显着改善常识推理建模。其代码、数据和微调模型可在https://github.com/HKUST-KnowComp/CAT上公开获取。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04808v2] CAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning](http://arxiv.org/abs/2305.04808v2) #language model</code></li>
</ul>
<h3>标题: Algebra Error Classification with Large Language Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06163v1">http://arxiv.org/abs/2305.06163v1</a></li>
<li>主要机构: University of Massachusetts Amherst</li>
<li>页数: 16</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 自动化反馈在学生回答开放式数学问题方面具有显著的潜力，可以在大规模上提高学习成果。自动化反馈系统的关键部分是错误分类组件，它可以识别学生的错误并启用适当的预定义反馈。大多数现有的错误分类方法使用基于规则的方法，其泛化能力有限。现有的数据驱动方法避免了这些限制，但需要将学生响应中的数学表达式解析为语法树。这个要求本身就是一个限制，因为学生的响应并不总是语法上有效的，不能转换成树。在这项工作中，我们介绍了一种使用预训练的大型语言模型的灵活的错误分类方法。我们证明了我们的方法可以在代数错误分类方面优于现有方法，并能够分类更大的学生响应集。此外，我们分析了我们的方法常见的分类错误，并讨论了自动化错误分类的限制。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06163v1] Algebra Error Classification with Large Language Models](http://arxiv.org/abs/2305.06163v1) #language model</code></li>
</ul>
<h3>标题: MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04790v2">http://arxiv.org/abs/2305.04790v2</a></li>
<li>主要机构: None</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: MultiModal-GPT是一种视觉和语言模型，可与人类进行多轮对话。它可以遵循人类的各种指令，如生成详细的标题，计算感兴趣的对象数量以及回答用户的一般问题。该模型使用OpenFlamingo进行参数高效微调，并在语言模型的交叉注意力部分和自我注意力部分中添加了低秩适配器（LoRA）。为了使模型理解和遵循人类指令，我们首先使用视觉和语言数据构建指令模板进行多模态指令调整。我们发现训练数据的质量对对话表现至关重要。为了进一步增强MultiModal-GPT与人类聊天的能力，我们利用仅语言的指令跟随数据共同训练MultiModal-GPT。使用相同的指令模板进行语言和视觉语言指令的联合训练有效提高了对话表现。各种演示展示了MultiModal-GPT与人类的持续对话能力。代码、数据集和演示位于https://github.com/open-mmlab/Multimodal-GPT。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04790v2] MultiModal-GPT: A Vision and Language Model for Dialogue with Humans](http://arxiv.org/abs/2305.04790v2) #language model</code></li>
</ul>
<h3>标题: AvatarReX: Real-time Expressive Full-body Avatars</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04789v1">http://arxiv.org/abs/2305.04789v1</a></li>
<li>主要机构: AvatarReX</li>
<li>页数: 19</li>
<li>论文接收情况: SIGGRAPH 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: AvatarReX是一种新的方法，可以从视频数据中学习基于NeRF的全身化身。该方法提供了对身体、手和面部的表达控制，并支持实时动画和渲染。为此，提出了一种组合化身表示，其中身体、手和面部分别建模，以适当利用参数化网格模板的结构先验，同时不影响表示灵活性。此外，对每个部分进行几何和外观的分离。通过这些技术设计，提出了一种专用的延迟渲染管道，可以以实时帧速率执行，以合成高质量的自由视图图像。几何和外观的分离还允许我们设计一种两阶段训练策略，将体积渲染和表面渲染结合起来进行网络训练。总体而言，该方法实现了具有实时渲染能力的自动构建表达丰富的全身化身，并可以为新的身体动作和面部表情生成具有动态细节的照片般逼真的图像。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04789v1] AvatarReX: Real-time Expressive Full-body Avatars](http://arxiv.org/abs/2305.04789v1) #language model</code></li>
</ul>
<h3>标题: BiRT: Bio-inspired Replay in Vision Transformers for Continual Learning</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04769v1">http://arxiv.org/abs/2305.04769v1</a></li>
<li>主要机构: BiRT</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 深度神经网络在连续学习和适应一系列任务方面的能力一直存在着灾难性遗忘之困。相比之下，人类具有在一生中获取、吸收和跨任务转移知识的非凡能力，而这种能力可以归因于抽象经验的演练。然而，视觉转换器中的表示演练缺乏多样性，导致过度拟合，因此性能显著下降。因此，我们提出了一种新颖的基于表示演练的连续学习方法BiRT，使用视觉转换器。具体而言，我们在视觉转换器的各个阶段引入建设性噪声，并强制要求预测与工作模型的指数移动平均值一致。我们的方法在几个具有挑战性的连续学习基准测试中提供了一致的性能提升，同时具有内存效率和对自然和对抗性破坏的鲁棒性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04769v1] BiRT: Bio-inspired Replay in Vision Transformers for Continual Learning](http://arxiv.org/abs/2305.04769v1) #language model</code></li>
</ul>
<h3>标题: Large-scale and Efficient Texture Mapping Algorithm via Loopy Belief Propagation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04763v1">http://arxiv.org/abs/2305.04763v1</a></li>
<li>主要机构: None</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种新的纹理映射框架，可以在面级别上使用多个视图的纹理，并实现全局颜色一致性。该方法利用循环置信传播算法进行高效的全局概率推理，以对每个面进行候选视图的排名，从而实现面级别的多视图纹理融合和混合。实验表明，该方法在不同类型的数据集上都能产生视觉上愉悦和纹理一致的结果，并且相对于现有的方法，尤其是对于卫星派生模型等大规模数据集，消耗的运行时间更少。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04763v1] Large-scale and Efficient Texture Mapping Algorithm via Loopy Belief Propagation](http://arxiv.org/abs/2305.04763v1) #language model</code></li>
</ul>
<h3>标题: Augmented Large Language Models with Parametric Knowledge Guiding</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04757v1">http://arxiv.org/abs/2305.04757v1</a></li>
<li>主要机构: HongKongBaptistUniversity</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 大型语言模型（LLMs）在语言理解和生成方面具有令人印象深刻的能力，显著推进了自然语言处理（NLP）的发展。然而，由于对特定领域知识和词汇的了解有限，它们在长尾或特定领域任务中的表现可能不够优秀。此外，大多数最先进的LLMs缺乏透明度，只能通过API访问，这阻碍了进一步使用自定义数据进行微调。此外，数据隐私是一个重要问题。为了解决这些挑战，我们提出了新颖的参数化知识引导（PKG）框架，为LLMs配备了一个知识引导模块，以在运行时访问相关知识，而不改变LLMs的参数。我们的PKG基于开源的“白盒”小型语言模型，允许离线存储LLMs需要的任何知识。我们证明了我们的PKG框架可以提高“黑盒”LLMs在需要事实、表格、医学和多模式知识的一系列长尾和特定领域下游任务的性能。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04757v1] Augmented Large Language Models with Parametric Knowledge Guiding](http://arxiv.org/abs/2305.04757v1) #language model</code></li>
</ul>
<h3>标题: Toeplitz Neural Network for Sequence Modeling</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04749v1">http://arxiv.org/abs/2305.04749v1</a></li>
<li>主要机构: ICLR2023</li>
<li>页数: 18</li>
<li>论文接收情况: ICLR 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种新的序列建模方法，使用相对位置编码的Toeplitz矩阵来降低空间和时间复杂度，相比于transformer模型，能够更高效地处理长序列。作者还提出了一个轻量级的子网络，用于生成相对位置系数，使得该模型能够处理不同长度的序列。实验结果表明，该方法在自回归和双向语言建模、图像建模以及长距离竞技场基准测试等任务中表现优异，且速度更快。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04749v1] Toeplitz Neural Network for Sequence Modeling](http://arxiv.org/abs/2305.04749v1) #language model</code></li>
</ul>
<h3>标题: Strategy for Rapid Diabetic Retinopathy Exposure Based on Enhanced Feature Extraction Processing</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04724v1">http://arxiv.org/abs/2305.04724v1</a></li>
<li>主要机构: Tech Science Press</li>
<li>页数: 17</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 糖尿病视网膜病变是一种严重的眼部感染，可能导致失明。早期诊断可以有效治疗，但由于症状轻微，因此很难检测。本研究旨在开发一种深度学习模型，用于及时识别糖尿病视网膜病变，比现有的基于CNN的模型更准确。该模型将从视网膜图像中检测出各种病变，并使用EDLM进行分类和特征提取。该模型在KAG GLE数据集上进行了评估，并与VGG16、VGG19、RESNET18、RESNET34和RESNET50进行了比较。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04724v1] Strategy for Rapid Diabetic Retinopathy Exposure Based on Enhanced Feature Extraction Processing](http://arxiv.org/abs/2305.04724v1) #language model</code></li>
</ul>
<h3>标题: Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04722v1">http://arxiv.org/abs/2305.04722v1</a></li>
<li>主要机构: POSTECH</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了一种名为ViT的视觉转换器，它将图像建模为分割的补丁序列，并使用位置嵌入来反映补丁的顺序。作者认为，位置嵌入并不能简单地保证ViT具有顺序感知能力。作者通过有效的感受野分析了ViT的实际行为，并提出了一种添加高斯注意偏差的方法，以指导位置嵌入从训练开始就具有相应的模式。实验结果表明，该方法不仅有助于ViT理解图像，而且在各种数据集上提高了其性能。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04722v1] Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields](http://arxiv.org/abs/2305.04722v1) #language model</code></li>
</ul>
<h3>标题: DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04720v1">http://arxiv.org/abs/2305.04720v1</a></li>
<li>主要机构: KAISTAI</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该研究提出了一种名为DEnsity的评估指标，通过利用神经分类器的特征空间进行密度估计来评估响应的可靠性。该指标能够更好地与人类评估相关，并利用对比学习进一步压缩特征空间以提高性能。实验表明，DEnsity比现有指标更好地与人类评估相关。该研究代码可在https://github.com/ddehun/DEnsity上获得。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04720v1] DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation](http://arxiv.org/abs/2305.04720v1) #language model</code></li>
</ul>
<h2>segmentation</h2>
<h3>标题: OSTA: One-shot Task-adaptive Channel Selection for Semantic Segmentation of Multichannel Images</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04766v1">http://arxiv.org/abs/2305.04766v1</a></li>
<li>主要机构: None</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本研究提出了一种基于超网络剪枝的一次性任务自适应（OSTA）通道选择方法，用于多通道图像的语义分割。该方法将通道选择和语义分割网络的训练整合在一起，通过三个阶段（超网络训练阶段、剪枝阶段和微调阶段）实现。实验结果表明，OSTA在所有测试中均取得了最高的分割精度，并且甚至超过了穷举测试的最高精度。此外，还发现了一些有价值的结果。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04766v1] OSTA: One-shot Task-adaptive Channel Selection for Semantic Segmentation of Multichannel Images](http://arxiv.org/abs/2305.04766v1) #segmentation</code></li>
</ul>
<h3>标题: SwinDocSegmenter: An End-to-End Unified Domain Adaptive Transformer for Document Instance Segmentation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04609v1">http://arxiv.org/abs/2305.04609v1</a></li>
<li>主要机构: None</li>
<li>页数: 19</li>
<li>论文接收情况: ICDAR 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文提出了一种统一的变压器编码器-解码器架构，用于端到端实例分割复杂布局的文档图像。该方法采用对比训练和混合查询选择进行锚点初始化，并在解码器中执行获得的查询嵌入和像素嵌入图之间的点积进行语义推理。在PubLayNet、PRIMA、Historical Japanese（HJ）和TableBank等竞争基准上进行了广泛的实验，证明了我们的模型在十亿个参数下比现有的最先进方法具有更好的分割性能。代码公开在github上。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04609v1] SwinDocSegmenter: An End-to-End Unified Domain Adaptive Transformer for Document Instance Segmentation](http://arxiv.org/abs/2305.04609v1) #segmentation</code></li>
</ul>
<h3>标题: Video Object Segmentation in Panoptic Wild Scenes</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04470v1">http://arxiv.org/abs/2305.04470v1</a></li>
<li>主要机构: ZhejiangUniversity</li>
<li>页数: 9</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了半监督视频对象分割（VOS）在全景野外场景中的应用，并提出了一个大规模基准以及一个基线方法。之前的VOS基准测试只有稀疏注释，无法训练或评估需要处理所有可能对象的模型。新的基准测试（VIPOSeg）包含详尽的对象注释，涵盖各种真实世界的对象类别，分为物品/材料和已知/未知类别进行全面评估。考虑到全景VOS的挑战，我们提出了一种强大的基线方法，名为具有变压器的全景对象关联（PAOT），它使用全景识别将对象与多尺度的金字塔架构关联起来。实验结果表明，VIPOSeg不仅可以通过全景训练提高VOS模型的性能，还可以在全景场景中进行全面评估。之前的经典VOS方法在处理全景场景时仍需要提高性能和效率，而我们的PAOT在VIPOSeg和之前的VOS基准测试中实现了SOTA性能和良好的效率。PAOT还在VOT2022挑战中排名第一。我们的数据集可在https://github.com/yoxu515/VIPOSeg-Benchmark上获得。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04470v1] Video Object Segmentation in Panoptic Wild Scenes](http://arxiv.org/abs/2305.04470v1) #segmentation</code></li>
</ul>
<h2>object detection</h2>
<h3>标题: Riesz networks: scale invariant neural networks in a single forward pass</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04665v1">http://arxiv.org/abs/2305.04665v1</a></li>
<li>主要机构: RPTU Kaiserslautern-Landau</li>
<li>页数: 40</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: Riesz网络是一种新型的尺度不变神经网络，它基于Riesz变换，可以在单次前向传递中自然地推广到未见过的或任意尺度。该网络在探测和分割混凝土断裂图像方面表现出色，并在MNIST大规模数据集上进行了额外实验。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04665v1] Riesz networks: scale invariant neural networks in a single forward pass](http://arxiv.org/abs/2305.04665v1) #object detection</code></li>
</ul>
<h3>标题: Pedestrian Behavior Maps for Safety Advisories: CHAMP Framework and Real-World Data Analysis</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04506v1">http://arxiv.org/abs/2305.04506v1</a></li>
<li>主要机构: UCSD</li>
<li>页数: 8</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 该系统使用在线地图为基础的行人检测聚合系统，学习常见的行人位置，解决了夜间或行人遮挡等问题。通过在加利福尼亚州La Jolla收集和注释的数据集，演示了该系统学习行人区域并在车辆接近行人时生成警告通知的能力。通过正确警告、错误警告和漏警告的数量来定义精度和召回率性能指标，评估了该系统，并讨论了进一步数据收集的未来积极影响。他们已经在https://github.com/s7desai/ped-mapping上提供了代码，并在https://youtu.be/dxeCrS_Gpkw上提供了CHAMP系统的视频演示。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04506v1] Pedestrian Behavior Maps for Safety Advisories: CHAMP Framework and Real-World Data Analysis](http://arxiv.org/abs/2305.04506v1) #object detection</code></li>
</ul>
<h3>标题: Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04446v1">http://arxiv.org/abs/2305.04446v1</a></li>
<li>主要机构: School of Computer Science and Te.</li>
<li>页数: 13</li>
<li>论文接收情况: ACL 2023</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了如何在中文网络语境下进行细粒度的有害语言检测。作者首先构建了一个层次化的有害类型和表达分析框架，并提出了一个包含直接和间接有害样本的数据集。其次，作者建立了一个包含隐含粗口的侮辱词汇表，并提出了一种基于词汇特征的有害语言检测方法。最后，作者对实验结果进行了定量和定性分析，证明了该方法的有效性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04446v1] Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks](http://arxiv.org/abs/2305.04446v1) #object detection</code></li>
</ul>
<h3>标题: Adversarial Examples Detection with Enhanced Image Difference Features based on Local Histogram Equalization</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04436v1">http://arxiv.org/abs/2305.04436v1</a></li>
<li>主要机构: IEEE</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 深度神经网络（DNN）在许多领域取得了显著进展，但研究表明，DNN容易受到对抗性示例的攻击。先前提出了各种防御方法，但已被证明这些方法只能对抗某些攻击，无法应对最新的未知攻击方法。因此，提出了一种基于高频信息增强策略的对抗性示例检测框架，可以有效地提取和放大对抗性示例和正常示例之间的特征差异。实验结果表明，该框架下的特征增强模块可以与现有的检测模型模块化地结合，提高检测器的性能并降低部署成本，而无需修改现有的检测模型。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04436v1] Adversarial Examples Detection with Enhanced Image Difference Features based on Local Histogram Equalization](http://arxiv.org/abs/2305.04436v1) #object detection</code></li>
</ul>
<h3>标题: TaLU: A Hybrid Activation Function Combining Tanh and Rectified Linear Unit to Enhance Neural Networks</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04402v1">http://arxiv.org/abs/2305.04402v1</a></li>
<li>主要机构: Springer Nature</li>
<li>页数: 15</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: 本文介绍了一种新的激活函数TaLU，它是Tanh和ReLU的组合，用于改善深度学习模型中激活函数对准确检测目标对象的影响。与ReLU相比，TaLU可以缓解ReLU的梯度消失问题，并在MNIST和CIFAR-10数据集上表现出更高的准确性。</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04402v1] TaLU: A Hybrid Activation Function Combining Tanh and Rectified Linear Unit to Enhance Neural Networks](http://arxiv.org/abs/2305.04402v1) #object detection</code></li>
</ul>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script>new ClipboardJS("#copy",{text:function(trigger){var res="[[2023-05-08]]\n\n";var input=document.querySelectorAll("input");for(var i=0;i<input.length;i++){if(input[i].type=="checkbox"&&input[i].checked){res+="- "+input[i].nextSibling.nodeValue+"\n"}}res+="\n";return res}}).on("success",function(e){e.clearSelection()});</script>
<button id="copy">Copy All</button>
