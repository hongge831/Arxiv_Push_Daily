<h2>diffusion</h2>
<h2>data-free</h2>
<h2>generative</h2>
<h3>标题: Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05061v1">http://arxiv.org/abs/2305.05061v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05061v1] Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer](http://arxiv.org/abs/2305.05061v1) #generative</code></li>
</ul>
<h3>标题: HistAlign: Improving Context Dependency in Language Generation by Aligning with History</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04782v1">http://arxiv.org/abs/2305.04782v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04782v1] HistAlign: Improving Context Dependency in Language Generation by Aligning with History](http://arxiv.org/abs/2305.04782v1) #generative</code></li>
</ul>
<h3>标题: Boosting Radiology Report Generation by Infusing Comparison Prior</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04561v1">http://arxiv.org/abs/2305.04561v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 9</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04561v1] Boosting Radiology Report Generation by Infusing Comparison Prior](http://arxiv.org/abs/2305.04561v1) #generative</code></li>
</ul>
<h2>language model</h2>
<h3>标题: Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05095v1">http://arxiv.org/abs/2305.05095v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05095v1] Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness](http://arxiv.org/abs/2305.05095v1) #language model</code></li>
</ul>
<h3>标题: Knowledge-enhanced Agents for Interactive Text Games</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05091v1">http://arxiv.org/abs/2305.05091v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05091v1] Knowledge-enhanced Agents for Interactive Text Games](http://arxiv.org/abs/2305.05091v1) #language model</code></li>
</ul>
<h3>标题: Multi-Task End-to-End Training Improves Conversational Recommendation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06218v1">http://arxiv.org/abs/2305.06218v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06218v1] Multi-Task End-to-End Training Improves Conversational Recommendation](http://arxiv.org/abs/2305.06218v1) #language model</code></li>
</ul>
<h3>标题: Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05023v2">http://arxiv.org/abs/2305.05023v2</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 19</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05023v2] Domain Agnostic Image-to-image Translation using Low-Resolution Conditioning](http://arxiv.org/abs/2305.05023v2) #language model</code></li>
</ul>
<h3>标题: Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge Distillation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.05010v1">http://arxiv.org/abs/2305.05010v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 16</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.05010v1] Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge Distillation](http://arxiv.org/abs/2305.05010v1) #language model</code></li>
</ul>
<h3>标题: ComputeGPT: A computational chat model for numerical problems</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.06223v1">http://arxiv.org/abs/2305.06223v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 12</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.06223v1] ComputeGPT: A computational chat model for numerical problems](http://arxiv.org/abs/2305.06223v1) #language model</code></li>
</ul>
<h3>标题: Reinforcement Learning for Topic Models</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04843v1">http://arxiv.org/abs/2305.04843v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 18</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04843v1] Reinforcement Learning for Topic Models](http://arxiv.org/abs/2305.04843v1) #language model</code></li>
</ul>
<h3>标题: MultiModal-GPT: A Vision and Language Model for Dialogue with Humans</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04790v2">http://arxiv.org/abs/2305.04790v2</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 10</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04790v2] MultiModal-GPT: A Vision and Language Model for Dialogue with Humans](http://arxiv.org/abs/2305.04790v2) #language model</code></li>
</ul>
<h3>标题: Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04722v1">http://arxiv.org/abs/2305.04722v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04722v1] Understanding Gaussian Attention Bias of Vision Transformers Using Effective Receptive Fields](http://arxiv.org/abs/2305.04722v1) #language model</code></li>
</ul>
<h3>标题: DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04720v1">http://arxiv.org/abs/2305.04720v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 13</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04720v1] DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation](http://arxiv.org/abs/2305.04720v1) #language model</code></li>
</ul>
<h2>transformer</h2>
<h3>标题: SNT: Sharpness-Minimizing Network Transformation for Fast Compression-friendly Pretraining</h3>
<ul>
<li>文章链接: <a href="http://arxiv.org/abs/2305.04526v1">http://arxiv.org/abs/2305.04526v1</a></li>
<li>主要机构: ['placeholder']</li>
<li>页数: 11</li>
<li>论文接收情况: None</li>
<li>代码链接: <a href="null">null</a></li>
<li>中文总结: placeholder</li>
<li>点击拷贝: <code><input type="checkbox">[[2305.04526v1] SNT: Sharpness-Minimizing Network Transformation for Fast Compression-friendly Pretraining](http://arxiv.org/abs/2305.04526v1) #transformer</code></li>
</ul>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script>new ClipboardJS("#copy",{text:function(trigger){var res="[[2023-05-08]]\n\n";var input=document.querySelectorAll("input");for(var i=0;i<input.length;i++){if(input[i].type=="checkbox"&&input[i].checked){res+="- "+input[i].nextSibling.nodeValue+"\n"}}res+="\n";return res}}).on("success",function(e){e.clearSelection()});</script>
<button id="copy">Copy All</button>
