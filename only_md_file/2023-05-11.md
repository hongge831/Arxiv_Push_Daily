## diffusion
### 标题: Exploiting Diffusion Prior for Real-World Image Super-Resolution
* 文章链接: [http://arxiv.org/abs/2305.07015v1](http://arxiv.org/abs/2305.07015v1)
* 主要机构: NanyangTechnologicalUniversity
* 页数: 15
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种新方法，利用预训练的文本到图像扩散模型中的先前知识来进行盲超分辨率。通过使用时间感知编码器，可以在不改变预训练合成模型的情况下实现有希望的恢复结果，从而保留生成先验并最小化训练成本。为了解决扩散模型固有随机性导致的保真度损失，引入了可控特征包装模块，使用户可以在推理过程中通过简单调整标量值来平衡质量和保真度。此外，还开发了渐进聚合采样策略，以克服预训练扩散模型的固定大小限制，实现对任何大小分辨率的适应。通过使用合成和真实世界基准的全面评估，证明了该方法优于当前最先进的方法。
### 标题: Generation of Structurally Realistic Retinal Fundus Images with Diffusion Models
* 文章链接: [http://arxiv.org/abs/2305.06813v1](http://arxiv.org/abs/2305.06813v1)
* 主要机构: None
* 页数: 9
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种使用扩散模型生成具有解剖学准确的血管结构的视网膜底图像的新技术。该方法可以生成具有更真实血管结构的高质量图像，并且可以根据扩散模型的强度创建各种不同的图像。研究还展示了该方法在血管分割和动脉/静脉分类的数据增强方面的性能提升，并通过临床专家的图灵测试结果表明，生成的图像难以与真实图像区分。该方法可以应用于构建与患者隐私无关的独立数据集。
### 标题: Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator
* 文章链接: [http://arxiv.org/abs/2305.06710v1](http://arxiv.org/abs/2305.06710v1)
* 主要机构: National University of Defense Technology
* 页数: 25
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了两种扰动方法，Rollback disturbance (Back-D) 和 Image disturbance (Image-D)，用于构建噪声图像和文本引导之间的错位，从而实现对噪声图像的卡通化处理。通过实验发现，扰动的有效性取决于噪声图像和源图像之间的相关性。这些方法可以生成卡通图像和卡通化特定图像，且无需训练，易于集成到任何无分类器引导扩散模型中。
## data-free
## generative
### 标题: SparseGNV: Generating Novel Views of Indoor Scenes with Sparse Input Views
* 文章链接: [http://arxiv.org/abs/2305.07024v1](http://arxiv.org/abs/2305.07024v1)
* 主要机构: ARCLab
* 页数: 10
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: SparseGNV是一种学习框架，结合了3D结构和图像生成模型，用于生成室内场景的新视角。它包括三个模块，第一个模块构建神经点云作为底层几何结构，提供上下文信息和目标新视角的指导。第二个模块利用基于转换器的网络将场景上下文和指导映射到共享的潜在空间，并自回归地解码离散图像令牌的目标视图。第三个模块将令牌重构为目标视图的图像。SparseGNV在大型室内场景数据集上进行训练，学习可推广的先验知识。一旦训练完成，它可以以前馈方式高效地生成未见过的室内场景的新视角。在真实世界和合成室内场景上评估SparseGNV，并证明它优于基于神经辐射场或条件图像生成的最先进方法。
### 标题: A General-Purpose Multilingual Document Encoder
* 文章链接: [http://arxiv.org/abs/2305.07016v1](http://arxiv.org/abs/2305.07016v1)
* 主要机构: None
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文介绍了一种新的方法，使用维基百科作为训练数据，预训练了一种大规模多语言文档编码器（HMDE），并通过跨语言对比目标进行训练。该编码器在两个跨语言文档级任务中表现出显著的优越性，比基于段落表示的聚合和多语言Longformer更加有效。此外，由于其大规模多语言的下层变压器，HMDE成功地推广到了文档级预训练中未见过的语言。作者公开了代码和模型。
### 标题: Subword Segmental Machine Translation: Unifying Segmentation and Target Sentence Generation
* 文章链接: [http://arxiv.org/abs/2305.07005v1](http://arxiv.org/abs/2305.07005v1)
* 主要机构: University of Cape Town
* 页数: 14
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: SSMT是一种新的子词分段机器翻译方法，将子词分段和机器翻译结合在一起，通过动态解码算法来生成翻译结果。实验表明，SSMT在形态丰富的语言中表现更好，特别是在低资源情况下。此外，SSMT还能够学习更接近词素的子词，并在测试集上表现更加稳健。
### 标题: Active Retrieval Augmented Generation
* 文章链接: [http://arxiv.org/abs/2305.06983v1](http://arxiv.org/abs/2305.06983v1)
* 主要机构: Language Technologies Institute
* 页数: 24
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 大型语言模型具有理解和生成语言的显著能力，但它们有产生虚假信息和事实不准确的倾向。通过从外部知识资源检索信息来增强语言模型是一种有前途的解决方案。现有的检索增强语言模型大多采用基于输入的一次检索和生成设置，这在生成长文本的更一般情况下是有限的，因为在生成过程中不断收集信息是必要的。本文提出了一种通用的检索增强生成方法，即前瞻性主动检索增强生成（FLARE），它迭代地使用即将出现的句子的预测来预测未来的内容，并将其用作查询来检索相关文档以重新生成句子。我们在4个长篇知识密集型生成任务/数据集上全面测试了FLARE和基线。FLARE在所有任务上都取得了优越或有竞争力的表现，证明了我们方法的有效性。代码和数据集可在https://github.com/jzbjyb/FLARE上获得。
### 标题: Generating high-quality 3DMPCs by adaptive data acquisition and NeREF-based reflectance correction to facilitate efficient plant phenotyping
* 文章链接: [http://arxiv.org/abs/2305.06777v1](http://arxiv.org/abs/2305.06777v1)
* 主要机构: None
* 页数: 42
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种自适应数据采集和反射校正方法，用于生成高质量的植物三维多光谱点云（3DMPCs）。该方法通过使用新型UGV平台和多传感器装备的机械臂，提出了一种高效的下一最佳视角（NBV）规划方法，以消除自然光条件下的主观视角选择和复杂照明效果对数据质量的影响。同时，使用神经参考场（NeREF）预测参考数字（DN）来消除照明效果。该方法在6个紫苏和6个番茄植物上进行了测试，选择了每个植物的2片可见叶子和4个感兴趣区域（ROIs）来评估生物量和叶绿素含量。该方法可以提高整个植物数据的完整性，使叶生物量估计的确定系数（R2）达到0.99和0.92，叶绿素含量估计的R2分别为0.91和0.93。该方法有望在自然光条件下生成高质量的植物3DMPCs，并促进准确的植物表型分析。
### 标题: WeditGAN: Few-shot Image Generation via Latent Space Relocation
* 文章链接: [http://arxiv.org/abs/2305.06671v1](http://arxiv.org/abs/2305.06671v1)
* 主要机构: MoEKeyLabofAI
* 页数: 16
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: WeditGAN是一种用于few-shot图像生成的模型，通过编辑StyleGAN中的中间潜在代码$w$，利用学习到的常量偏移量($\Delta w$)实现模型转移，从而避免过拟合的风险。WeditGAN通过简单地重新定位源潜在空间的分布，发现和构建目标潜在空间，建立潜在空间之间的一对一映射，自然地防止了模式崩溃和过拟合。此外，WeditGAN还提出了一些变体，通过规范化方向或微调$\Delta w$的强度进一步增强了重定位过程。实验表明，WeditGAN在生成逼真且多样化的图像方面非常有效。
### 标题: Enabling Programming Thinking in Large Language Models Toward Code Generation
* 文章链接: [http://arxiv.org/abs/2305.06599v1](http://arxiv.org/abs/2305.06599v1)
* 主要机构: Key Lab of High Con♂fidence Software
* 页数: 11
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种名为TiP的方法，旨在解锁大型语言模型（LLMs）在代码生成中的编程思维。TiP将代码生成分解为两个步骤，并逐步引导LLMs分析和实现编程逻辑。具体而言，TiP首先生成一个代码草图，提供使用编程逻辑的高级解决过程，但省略了实现细节（例如API）。然后，TiP使用特定的编程语言将草图实现为程序。实验结果表明，TiP在三个公共基准测试中优于ChatGPT，且在正确性、代码质量和可维护性方面优于ChatGPT。此外，本文还探讨了TiP与后处理方法（例如CodeT）之间的互补性。
### 标题: V2Meow: Meowing to the Visual Beat via Music Generation
* 文章链接: [http://arxiv.org/abs/2305.06594v1](http://arxiv.org/abs/2305.06594v1)
* 主要机构: None
* 页数: 16
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种名为V2Meow的新方法，可以生成与各种视频输入类型的视觉语义相匹配的高质量音频。该方法是一个多阶段自回归模型，通过与视频帧配对的O（100K）音频剪辑进行训练，不涉及并行符号音乐数据。V2Meow能够仅基于从任意静态视频剪辑中提取的预训练视觉特征合成高保真度的音乐音频波形，并且还通过支持文本提示来控制生成示例的音乐风格。通过定性和定量评估，我们证明了我们的模型在视觉-音频对应和音频质量方面优于几种现有的音乐生成系统。
### 标题: A First Look at LLM-Powered Generative News Recommendation
* 文章链接: [http://arxiv.org/abs/2305.06566v1](http://arxiv.org/abs/2305.06566v1)
* 主要机构: TheHongKongPolytechnicUniversity
* 页数: 11
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: GENRE是一种基于LLM的生成式新闻推荐框架，利用预训练的语义知识来丰富新闻数据，提供了一种灵活和统一的新闻推荐解决方案。该框架可用于个性化新闻生成、用户画像和新闻摘要。通过与各种流行的推荐模型进行广泛实验，证明了GENRE的有效性。该研究将发布代码和数据，供其他研究人员复现。
### 标题: KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment
* 文章链接: [http://arxiv.org/abs/2305.06535v1](http://arxiv.org/abs/2305.06535v1)
* 主要机构: The Chinese University of Hong Kong
* 页数: 11
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 最近的“被遗忘权”立法引起了对机器遗忘的兴趣，其中学习模型被赋予了忘记特定训练实例信息的功能，就像它们从未存在于训练集中一样。本文提出了一个通用的遗忘框架KGA，用于诱导遗忘。与以前的工作主要关注计算机视觉场景并在NLP领域中大量忽略遗忘的基本要素不同，文本数据包含比图像更明确和敏感的个人信息。此外，我们首次将遗忘方法应用于各种NLP任务（即分类、翻译、响应生成），并提出了几个与相关性的遗忘评估指标。大规模数据集上的实验表明，KGA相对于基线产生了全面的改进，而广泛的分析进一步验证了KGA的有效性，并为NLP任务的遗忘提供了洞察。
### 标题: InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning
* 文章链接: [http://arxiv.org/abs/2305.06500v1](http://arxiv.org/abs/2305.06500v1)
* 主要机构: None
* 页数: 17
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文研究了基于预训练的BLIP-2模型的视觉语言指令调整，并引入了指令感知的视觉特征提取方法。通过在26个公开数据集上进行实验，InstructBLIP模型在零-shot评估中取得了最先进的性能，并在下游任务中实现了最先进的性能。此外，InstructBLIP模型还展示了优于其他多模型的优势。所有InstructBLIP模型均已开源。
## language model
### 标题: EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention
* 文章链接: [http://arxiv.org/abs/2305.07027v1](http://arxiv.org/abs/2305.07027v1)
* 主要机构: TheChineseUniversityofHongKong
* 页数: 11
* 论文接收情况: CVPR 2023
* 代码链接: [null](null)
* 中文总结: 本文提出了一种名为EfficientViT的高速视觉Transformer模型，旨在解决现有Transformer模型计算量大的问题。作者发现，现有Transformer模型的速度通常受到内存效率低下的操作的限制，特别是在MHSA中的张量重塑和逐元素函数。因此，作者设计了一种新的构建块，使用单个内存限制的MHSA在高效的FFN层之间，从而提高内存效率并增强通道通信。此外，作者发现注意力图在头部之间共享高度相似性，导致计算冗余。为了解决这个问题，作者提出了一个级联组注意力模块，将全特征的不同分裂馈送到注意力头部，从而节省计算成本并提高注意力多样性。综合实验表明，EfficientViT在速度和准确性之间取得了良好的平衡，优于现有的高效模型。与最近的高效模型MobileViT-XXS相比，EfficientViT-M2在GPU / CPU上运行速度分别快了5.8倍/3.7倍，并且在转换为ONNX格式时快了7.4倍。
### 标题: Simple Token-Level Confidence Improves Caption Correctness
* 文章链接: [http://arxiv.org/abs/2305.07021v1](http://arxiv.org/abs/2305.07021v1)
* 主要机构: UCBerkeley
* 页数: 15
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种名为TLC的方法，用于评估图像描述的正确性。通过对图像和提议的标题进行输入，利用代数或学习的令牌置信度来估计图像-标题一致性。与预训练模型的序列级得分相比，TLC在SVO-Probes的动词理解方面实现了10%的相对精度提高，并在Winoground的组合推理方面相对提高了37%和9%的得分。当有训练数据时，学习置信度估计器可以进一步提高性能，相对于原始模型，可以将MS COCO Captions中的对象幻觉率降低30%以上，并创造新的最高水平。
### 标题: Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts
* 文章链接: [http://arxiv.org/abs/2305.07019v1](http://arxiv.org/abs/2305.07019v1)
* 主要机构: None
* 页数: 14
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: Musketeer是一个序列到序列的视觉语言模型，其参数在所有任务上联合训练并在多个任务之间完全共享，通过Task Explanation Prompt（TEP）实现异构任务之间的知识集成。使用单个模型，Musketeer在多个任务上实现了与单个任务训练的强基线相当或更好的结果。
### 标题: An Inverse Scaling Law for CLIP Training
* 文章链接: [http://arxiv.org/abs/2305.07017v1](http://arxiv.org/abs/2305.07017v1)
* 主要机构: UCSantaCruz
* 页数: 14
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文发现了一个逆比例尺度定律，即使用更大的图像/文本编码器可以缩短图像/文本令牌的序列长度，从而降低了CLIP训练的成本。通过这一发现，作者成功地使用学术资源训练了CLIP，并在ImageNet上取得了不错的结果。作者希望通过降低CLIP的计算难度，鼓励更多学术界的研究。
### 标题: Virtual Occlusions Through Implicit Depth
* 文章链接: [http://arxiv.org/abs/2305.07014v1](http://arxiv.org/abs/2305.07014v1)
* 主要机构: Niantic
* 页数: 18
* 论文接收情况: CVPR 2023
* 代码链接: [null](null)
* 中文总结: 本文提出了一种新的增强现实技术，通过使用隐式深度模型直接预测遮挡掩模，而不需要深度回归作为中间步骤。该方法在ScanNetv2数据集上取得了最先进的遮挡结果，并在实际场景中获得了更好的定性结果。
### 标题: Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers
* 文章链接: [http://arxiv.org/abs/2305.07011v1](http://arxiv.org/abs/2305.07011v1)
* 主要机构: GoogleResearch
* 页数: 14
* 论文接收情况: CVPR 2023
* 代码链接: [null](null)
* 中文总结: RO-ViT是一种对比图像-文本预训练方法，旨在弥合图像级预训练和开放词汇物体检测之间的差距。在预训练阶段，RO-ViT提出随机裁剪和调整位置嵌入的区域，而不是使用整个图像的位置嵌入，以更好地匹配检测微调阶段的区域级位置嵌入。此外，RO-ViT将对比学习中常见的softmax交叉熵损失替换为focal损失，以更好地学习信息丰富但难以处理的示例。最后，RO-ViT利用最近的新物体提议技术来改进开放词汇检测微调。在LVIS和COCO开放词汇检测基准测试和零-shot转移上，RO-ViT的全模型评估达到了32.1 $AP_r$，超过了现有最佳方法5.8个点，并具有竞争性的零-shot转移检测。令人惊讶的是，RO-ViT还改进了图像级表示，并在COCO和Flickr图像-文本检索基准测试的12个指标中的9个指标上达到了最先进水平，超过了具有更大模型的竞争方法。
### 标题: Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting
* 文章链接: [http://arxiv.org/abs/2305.07004v1](http://arxiv.org/abs/2305.07004v1)
* 主要机构: None
* 页数: 32
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文介绍了一种名为跨语言思维提示（XLT）的简单而有效的方法，用于系统地提高大型语言模型（LLMs）的多语言能力。XLT是一种通用的模板提示，可以刺激跨语言和逻辑推理技能，以增强不同语言的任务表现。实验结果表明，XLT不仅显著提高了各种多语言任务的性能，而且还显著缩小了不同语言中每个任务的平均性能和最佳性能之间的差距。值得注意的是，XLT在算术推理和开放领域问答任务中带来了超过10个平均改进点。
### 标题: Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach
* 文章链接: [http://arxiv.org/abs/2305.07001v1](http://arxiv.org/abs/2305.07001v1)
* 主要机构: None
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 推荐系统一直受到研究和工业界的关注，许多研究致力于开发有效的推荐模型。本文提出了一种新的方法，将推荐视为LLMs的指令遵循，以自然语言描述用户偏好和需求，通过指令调整LLMs以更好地适应推荐系统。通过实验表明，该方法在多个任务上优于竞争基线，包括强大的GPT-3.5。该方法为开发更用户友好的推荐系统提供了新思路。
### 标题: Self-Chained Image-Language Model for Video Localization and Question Answering
* 文章链接: [http://arxiv.org/abs/2305.06988v1](http://arxiv.org/abs/2305.06988v1)
* 主要机构: UNCChapelHill
* 页数: 20
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种名为SeViLA的新框架，利用单个图像-语言模型（BLIP-2）来解决视频的时间关键帧定位和问答问题。SeViLA框架由两个模块组成：定位器和回答器，两者都是从BLIP-2中经过参数优化微调而来。该框架通过级联推理和自我细化来实现。SeViLA在五个视频问答和事件预测任务中表现优异，达到了最先进的水平。
### 标题: Evaluating Open-Domain Question Answering in the Era of Large Language Models
* 文章链接: [http://arxiv.org/abs/2305.06984v1](http://arxiv.org/abs/2305.06984v1)
* 主要机构: University of Alberta
* 页数: 14
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 本文指出，词汇匹配仍然是开放领域问答（QA）的事实评估方法。然而，当一个合理的候选答案没有出现在黄金答案列表中时，词汇匹配完全失败，随着我们从抽取模型转向生成模型，这种情况越来越普遍。大型语言模型（LLMs）在QA方面的最近成功加剧了词汇匹配的失败，因为候选答案变得更长，从而使与黄金答案的匹配变得更加具有挑战性。没有准确的评估，开放领域QA的真正进展仍然未知。本文通过手动评估NQ-open的子集，对各种开放领域QA模型进行了彻底分析，包括LLMs。我们的评估结果表明，虽然所有模型的真实性能都被严重低估，但InstructGPT（零-shot）LLM的性能增加了近60％，使其与现有的顶级模型相当，并且InstructGPT（few-shot）模型实际上在NQ-open上实现了新的最新技术。我们还发现，超过50％的词汇匹配失败归因于语义上等效的答案。我们进一步证明，正则表达式匹配与人类判断一致地排名QA模型，尽管仍然受到不必要的严格限制。最后，我们证明，自动评估模型在某些情况下是词汇匹配的合理替代品，但对于LLMs生成的长格式答案则不然。自动模型难以检测LLM答案中的幻觉，因此无法评估LLMs。目前，似乎没有替代人工评估的方法。
### 标题: Meta-hallucinator: Towards Few-Shot Cross-Modality Cardiac Image Segmentation
* 文章链接: [http://arxiv.org/abs/2305.06978v1](http://arxiv.org/abs/2305.06978v1)
* 主要机构: Nanyang Technological Univers.
* 页数: 13
* 论文接收情况: MICCAI 2022
* 代码链接: [null](null)
* 中文总结: 本文提出了一种新的元学习框架——元幻觉器，用于实现跨模态医学图像分割的有效少样本学习。该框架通过联合训练幻觉和分割模型，使用基于梯度的元学习策略来合成有助于提高目标域分割性能的样本。同时，为了进一步促进数据幻觉和跨域知识转移，我们开发了一种具有幻觉一致性属性的自我集成模型。实验结果表明，我们的方法在少样本无监督域自适应场景下，相对于其他方法表现更好。
### 标题: FreePoint: Unsupervised Point Cloud Instance Segmentation
* 文章链接: [http://arxiv.org/abs/2305.06973v1](http://arxiv.org/abs/2305.06973v1)
* 主要机构: FreePoint
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: FreePoint是一种用于点云的无监督类别不可知实例分割的方法。该方法使用自监督深度特征将点特征表示为坐标、颜色和法线的组合，并使用多切割算法将点云分割成粗略的实例掩模作为伪标签，用于训练点云实例分割模型。此外，该方法还提出了一种弱监督训练策略和相应的损失，以减轻训练过程中粗略掩模的不准确性。FreePoint还可以作为有限注释的监督语义实例分割的无监督预训练预文本。在点云的类别不可知实例分割方面，FreePoint在Mask3D模型的全监督对应物的基础上填补了空白，并甚至超过了一些以前的全监督方法。在作为预文本任务并在S3DIS上微调时，FreePoint仅使用10%的掩模注释就比从头开始训练提高了5.8%的AP。
### 标题: HuManiFlow: Ancestor-Conditioned Normalising Flows on SO(3) Manifolds for Human Pose and Shape Distribution Estimation
* 文章链接: [http://arxiv.org/abs/2305.06968v1](http://arxiv.org/abs/2305.06968v1)
* 主要机构: University of Cambridge
* 页数: 18
* 论文接收情况: CVPR 2023
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种名为HuManiFlow的方法，用于预测准确、一致和多样化的概率分布，以解决单目3D人体姿态和形状估计的不适定问题。该方法使用人类运动学树将全身姿态分解为祖先条件下的每个身体部位姿态分布，并使用规范化流来实现每个身体部位姿态的李群结构。该方法避免了常见的3D点估计损失，提高了样本多样性。
### 标题: Transformers for CT Reconstruction From Monoplanar and Biplanar Radiographs
* 文章链接: [http://arxiv.org/abs/2305.06965v1](http://arxiv.org/abs/2305.06965v1)
* 主要机构: None
* 页数: 11
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种基于变压器架构的新方法，通过将X射线嵌入潜在量化码本向量中，从而重建CT图像。该方法可用于诊断各种疾病和测量器官体积，同时避免了患者接受过多的辐射。该研究已在GitHub上公开发布代码，以鼓励进一步研究。
### 标题: Cascaded Cross-Attention Networks for Data-Efficient Whole-Slide Image Classification Using Transformers
* 文章链接: [http://arxiv.org/abs/2305.06963v1](http://arxiv.org/abs/2305.06963v1)
* 主要机构: None
* 页数: 12
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: Whole-Slide Imaging技术可以捕捉和数字化组织切片的高分辨率图像，使用深度学习模型进行自动分析因此需求量很高。Transformer架构被提出作为有效利用高分辨率信息的可能候选者。在这里，整个切片图像被分成较小的图像块，并从这些图像块中提取特征令牌。然而，虽然传统的Transformer允许同时处理大量输入令牌，但计算需求随着输入令牌数量呈二次方增长，因此随着图像块数量呈二次方增长。为了解决这个问题，我们提出了一种基于交叉注意机制的级联交叉注意网络（CCAN），其随着提取的图像块数量呈线性扩展。我们的实验表明，这种架构至少与其他基于注意力的最先进方法相当甚至更好，我们在两个公共数据集上展示了这一点：在肺癌（TCGA NSCLC）的用例中，我们的模型达到了0.970±0.008的平均接收器操作特征（AUC），在肾癌（TCGA RCC）中达到了0.985±0.004的平均AUC。此外，我们展示了我们提出的模型在低数据环境中的高效性，使其成为在资源有限的情况下分析整个切片图像的有前途的方法。为了促进这个方向的研究，我们在GitHub上公开了我们的代码：XXX。
### 标题: EAML: Ensemble Self-Attention-based Mutual Learning Network for Document Image Classification
* 文章链接: [http://arxiv.org/abs/2305.06923v1](http://arxiv.org/abs/2305.06923v1)
* 主要机构: IJDAR-ICDAR 2021 Journal Track
* 页数: 22
* 论文接收情况: IJDAR 2021
* 代码链接: [null](null)
* 中文总结: 本文提出了一种基于自注意力融合模块的互相学习方法，用于文档图像分类。该方法可以同时学习图像和文本模态的判别特征，并在训练阶段传递正面知识以促进互相学习。实验结果表明，该方法在单模态和多模态下均具有较高的准确性，优于基准数据集RVL-CDIP和Tobacco-3482的最新分类结果。
### 标题: CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model
* 文章链接: [http://arxiv.org/abs/2305.06908v1](http://arxiv.org/abs/2305.06908v1)
* 主要机构: CoMoSpeech
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种基于一致性模型的语音合成方法CoMoSpeech，通过单一扩散采样步骤实现高质量的语音合成。该方法通过从设计良好的扩散模型中提取一致性模型来实现一致性约束，最终在提取的CoMoSpeech中产生卓越的性能。实验结果表明，CoMoSpeech在单个NVIDIA A100 GPU上实现了超过150倍的实时推理速度，与FastSpeech2相当，使得基于扩散采样的语音合成真正实用。同时，对文本到语音和歌唱声音合成的客观和主观评估表明，所提出的教师模型产生了最佳的音频质量，而基于一步采样的CoMoSpeech在更好或与其他传统的多步扩散模型基线相当的音频质量下实现了最佳的推理速度。
### 标题: AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages
* 文章链接: [http://arxiv.org/abs/2305.06897v1](http://arxiv.org/abs/2305.06897v1)
* 主要机构: AfriQA
* 页数: 20
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 非洲语言数字内容较少，使得问答系统难以满足用户的信息需求。跨语言开放检索问答系统（XOR QA）可以从其他语言中检索答案内容，为填补这一空白提供了一种手段。为此，我们创建了AfriQA，这是第一个专注于非洲语言的跨语言QA数据集，包括10种非洲语言的12,000多个XOR QA示例。我们的实验表明，自动翻译和多语言检索方法的性能较差。总体而言，AfriQA对最先进的QA模型具有挑战性。我们希望该数据集能够促进更加公平的QA技术的发展。
### 标题: IUST_NLP at SemEval-2023 Task 10: Explainable Detecting Sexism with Transformers and Task-adaptive Pretraining
* 文章链接: [http://arxiv.org/abs/2305.06892v1](http://arxiv.org/abs/2305.06892v1)
* 主要机构: IUST (Iran University of Science and Technology)
* 页数: 8
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 本文介绍了我们在SemEval-2023任务10上的系统：可解释的在线性别歧视检测（EDOS）。该工作旨在设计一种自动系统，用于检测和分类在线空间中的性别歧视内容。我们提出了一组基于Transformer的预训练模型，具有任务自适应预训练和集成学习。我们系统的主要贡献包括分析不同基于Transformer的预训练模型的性能并组合这些模型，以及提供一种使用大量未标记数据进行模型自适应预训练的有效方法。我们还探索了几种其他策略。在测试数据集上，我们的系统在子任务A、B和C上分别实现了83％、64％和47％的F1分数。
### 标题: WebCPM: Interactive Web Search for Chinese Long-form Question Answering
* 文章链接: [http://arxiv.org/abs/2305.06849v1](http://arxiv.org/abs/2305.06849v1)
* 主要机构: None
* 页数: 19
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: WebCPM是第一个中文长篇问答数据集，其信息检索基于交互式网络搜索，可以实时与搜索引擎交互。该数据集收集了5500个高质量的问题-答案对，以及14315个支持事实和121330个网络搜索行为。研究人员使用预训练语言模型微调来模拟人类的网络搜索行为，并基于收集的事实生成答案。在数据集和DuReader上，使用这些微调模型构建的LFQA管道生成的答案在32.5％和47.5％的情况下不劣于人类编写的答案。
### 标题: Think Twice: Measuring the Efficiency of Eliminating Prediction Shortcuts of Question Answering Models
* 文章链接: [http://arxiv.org/abs/2305.06841v1](http://arxiv.org/abs/2305.06841v1)
* 主要机构: Faculty of Informatics
* 页数: 14
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种简单的方法来评估预训练模型在识别任务中对偏见特征的依赖程度，并评估了各种预训练模型和去偏见方法在问答中的鲁棒性。研究发现，去偏见方法的OOD增益不能通过减少对有偏见特征的依赖来解释，这表明偏见在QA数据集中是共享的。研究还发现，OOD模型的性能与ID模型相比，依赖于偏见特征的程度相似，这促使未来的研究将LLMs的鲁棒性报告精细到已知偏见特征的水平。
### 标题: Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning
* 文章链接: [http://arxiv.org/abs/2305.06801v1](http://arxiv.org/abs/2305.06801v1)
* 主要机构: GhentUniversity-Imec
* 页数: 8
* 论文接收情况: MWE 2023
* 代码链接: [null](null)
* 中文总结: 本文研究了基于定义的语义模型在临床术语中检测习语和半习语多词表达式（MWEs）方面的潜力。研究重点是在UMLS本体中定义的生物医学实体，并旨在帮助优先考虑这些实体的翻译工作。我们开发了一种有效的工具，用于评分生物医学MWEs的习惯用法，该工具基于这些MWEs的语义表示与其组成部分的表示的加权平均值之间的相似度。我们使用一个生物医学语言模型BioLORD来实现这一点，该模型经过训练，可以为实体名称和其定义生成类似的表示。通过将BioLORD模型与基于Transformer的两个其他最先进的生物医学语言模型SapBERT和CODER进行比较，突出了这种基于定义的方法的重要性。我们的结果表明，BioLORD模型具有强大的识别习语MWEs的能力，其他模型无法复制。我们的无语料库习惯用法估计有助于本体翻译人员集中处理更具挑战性的MWEs。
### 标题: COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks
* 文章链接: [http://arxiv.org/abs/2305.06754v1](http://arxiv.org/abs/2305.06754v1)
* 主要机构: IRIT
* 页数: 15
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 本文介绍了一种名为COCKATIEL的新型XAI技术，它是一种后处理、基于概念、模型无关的技术，通过使用非负矩阵分解（NMF）发现模型用于进行预测的概念，并利用敏感性分析准确估计每个概念对模型的重要性，从而生成有意义的解释。实验表明，COCKATIEL能够在不需要监督的情况下发现与人类一致的概念，并且能够提供有意义的解释。
### 标题: Advancing Neural Encoding of Portuguese with Transformer Albertina PT-*
* 文章链接: [http://arxiv.org/abs/2305.06721v1](http://arxiv.org/abs/2305.06721v1)
* 主要机构: University of Lisbon
* 页数: 10
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究开发了一种基于Transformer的编码器模型，名为Albertina PT- *，用于提高葡萄牙语（PT）的神经编码和数字化技术准备。该模型在欧洲葡萄牙语（PT-PT）和巴西葡萄牙语（PT-BR）两个变体中创造了新的技术水平。该模型使用DeBERTa作为起点，并在葡萄牙语数据集上进行预训练。该模型已经在葡萄牙语处理任务中得到了验证，并且可以在消费级硬件上运行。该模型免费分发，旨在促进葡萄牙语语言技术的研究和创新。
### 标题: Bi-level Dynamic Learning for Jointly Multi-modality Image Fusion and Beyond
* 文章链接: [http://arxiv.org/abs/2305.06720v1](http://arxiv.org/abs/2305.06720v1)
* 主要机构: Dalian University of Technology
* 页数: 9
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种层次双任务驱动的深度模型，用于多模态场景感知任务，包括图像融合和场景理解。该模型通过构建图像融合模块和级联的双任务相关模块来实现任务之间的桥接。该模型不仅能够产生视觉上令人愉悦的融合结果，而且在检测和分割方面也实现了显著的提升。
### 标题: Deep Visual-Genetic Biometrics for Taxonomic Classification of Rare Species
* 文章链接: [http://arxiv.org/abs/2305.06695v1](http://arxiv.org/abs/2305.06695v1)
* 主要机构: None
* 页数: 10
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种通过深度嵌入模型实现视觉-遗传推理空间对齐的方法，以提高对稀有类别的视觉分类性能。该方法可用于提高长尾识别（LTR）的性能，特别是对于稀有物种。实验结果表明，视觉-遗传对齐可以显著提高对最稀有物种的识别性能。该方法可作为将遗传和图像学整合到分类学空间中的重要工具。
### 标题: INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Large Language Models
* 文章链接: [http://arxiv.org/abs/2305.06677v1](http://arxiv.org/abs/2305.06677v1)
* 主要机构: None
* 页数: 12
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 大型预训练语言模型具有显著的泛化能力和新能力，但训练时间长、计算成本高、环境影响大。现有的优化方法主要集中在模型架构、训练流程和损失函数设计上，忽略了训练数据的效用。本文提出使用子模块优化选择高度代表性的训练数据子集，可以在保持下游性能的情况下，使用少量数据高效地训练多个预训练语言模型。
### 标题: QURG: Question Rewriting Guided Context-Dependent Text-to-SQL Semantic Parsing
* 文章链接: [http://arxiv.org/abs/2305.06655v1](http://arxiv.org/abs/2305.06655v1)
* 主要机构: StateKeyLabofSoftwareDe.
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种名为QURG的新方法，旨在帮助模型实现足够的上下文理解，将多轮自然语言问题转化为SQL查询。该方法首先训练一个问题重写模型，根据问题上下文完成当前问题，并将其转换为重写编辑矩阵。然后设计了一个双流矩阵编码器，共同建模问题和上下文之间的重写关系以及自然语言和结构化模式之间的模式链接关系。实验结果表明，QURG显著提高了两个大规模上下文相关数据集SParC和CoSQL的性能，特别是对于难以处理和长轮次的问题。
### 标题: PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive Summarization
* 文章链接: [http://arxiv.org/abs/2305.06647v1](http://arxiv.org/abs/2305.06647v1)
* 主要机构: Department of Computer Science and Engineering
* 页数: 14
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种新的短语级别的复制机制PROM，通过增强对n-gram的关注，提高了预训练模型在摘要生成中的性能。PROM在指示层上添加了一个指示器，以明确地选择可以从源中复制的n-gram中的标记，并计算复制预测的辅助损失。实证研究表明，PROM在基准测试的微调中取得了显著的改进。在零-shot设置中，PROM用于原始语料库的自监督预训练，并在广泛的摘要数据集上提供了新的基线。进一步的分析表明，PROM执行更合理的复制并有助于保真度。
### 标题: Object based Bayesian full-waveform inversion for shear elastography
* 文章链接: [http://arxiv.org/abs/2305.06646v1](http://arxiv.org/abs/2305.06646v1)
* 主要机构: Universidad Complutense de Madrid
* 页数: 35
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文提出了一种计算框架，用于量化组织异常的剪切弹性成像的不确定性。采用贝叶斯推断公式，通过观察数据、前向模型和它们的不确定性，找到代表异常几何形状和剪切模量的参数场的后验概率。为了构建先验概率，利用相关目标函数的拓扑能量。在合成的二维测试中展示了该方法，包括平滑和不规则形状。通过马尔可夫链蒙特卡罗（MCMC）技术对后验分布进行采样，获得剪切模量和异常几何特性的统计信息。对于低到中维度参数集所描述的形状，一般的仿射不变集合MCMC采样器是适当的。然而，MCMC方法计算成本高昂。对于简单的形状，我们设计了一种快速优化方案，计算代表最可能参数值的最大后验概率（MAP）估计。然后，通过在MAP点附近线性化找到的高斯分布来近似后验分布，以低计算成本捕获主模式。
### 标题: When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks
* 文章链接: [http://arxiv.org/abs/2305.06626v1](http://arxiv.org/abs/2305.06626v1)
* 主要机构: UCBerkeley
* 页数: 10
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究构建了一个模型，预测潜在冒犯性文本的个体注释者评分，并将这些信息与文本的目标群体预测相结合，以建模目标群体成员的意见。研究表明，注释者的评分可以使用他们的人口统计信息和在线内容意见进行预测，而无需跟踪标识注释者ID。同时，使用非侵入式调查问题有助于最大程度地保护隐私和最小化收集人口统计信息的必要性。该模型在预测个体注释者评分和注释者差异方面表现出色，提高了基线预测22％和33％。
### 标题: Improving Continual Relation Extraction by Distinguishing Analogous Semantics
* 文章链接: [http://arxiv.org/abs/2305.06620v1](http://arxiv.org/abs/2305.06620v1)
* 主要机构: State Key Laboratory for Novel Software Technology
* 页数: 12
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种新的持续关系提取模型，旨在解决现有模型在处理类似关系时容易出现过拟合问题的缺陷。该模型采用记忆无关的关系原型和记忆增强技术，同时引入综合训练和焦点知识蒸馏等方法，有效提高了模型的性能和区分类似关系的能力。实验结果表明，该模型具有优越性能，能够有效地克服过拟合问题。
### 标题: Serial Contrastive Knowledge Distillation for Continual Few-shot Relation Extraction
* 文章链接: [http://arxiv.org/abs/2305.06616v1](http://arxiv.org/abs/2305.06616v1)
* 主要机构: State Key Laboratory for Novel Software Technology
* 页数: 12
* 论文接收情况: ACL 2023
* 代码链接: [null](null)
* 中文总结: 本文提出了一种新的模型SCKD，旨在解决连续少样本关系抽取任务中旧关系的灾难性遗忘和数据稀疏性引起的过拟合等挑战。该模型采用串行知识蒸馏来保留以前模型的先前知识，并使用伪样本进行对比学习，以保持不同关系样本的表示足够可区分。实验结果表明，SCKD在连续少样本关系抽取任务中具有有效性，并且在知识转移和内存利用方面优于现有模型。
### 标题: Autocorrelations Decay in Texts and Applicability Limits of Language Models
* 文章链接: [http://arxiv.org/abs/2305.06615v1](http://arxiv.org/abs/2305.06615v1)
* 主要机构: Higher IT School
* 页数: 106
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文研究了文本中自相关衰减规律与语言模型适用性限制之间的密切关系。通过分布语义学的实证研究，我们发现文本中单词的自相关衰减符合幂律分布。我们还证明了分布语义学为多语言翻译的文本提供了一致的自相关衰减指数。生成文本的自相关衰减在数量和质量上与文学文本有所不同。我们得出结论，表现马尔可夫行为的语言模型，包括大型自回归语言模型，在分析或生成长文本时可能存在限制。
### 标题: BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from Book Reviews
* 文章链接: [http://arxiv.org/abs/2305.06595v1](http://arxiv.org/abs/2305.06595v1)
* 主要机构: Department of Computer Science and Engineering
* 页数: 8
* 论文接收情况: Findings 2023
* 代码链接: [null](null)
* 中文总结: 本文介绍了BanglaBook数据集，该数据集包含158,065个样本，分为积极、消极和中性三个类别，用于研究Bangla语言的情感分析。作者使用了多种机器学习模型，包括SVM、LSTM和Bangla-BERT，并发现预训练模型比手动特征模型表现更好。此外，作者还对情感单词进行了深入的错误分析，以便更好地理解Bangla语言等资源匮乏语言的分类错误。数据和代码公开在https://github.com/mohsinulkabir14/BanglaBook。
### 标题: SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2)
* 文章链接: [http://arxiv.org/abs/2305.06586v1](http://arxiv.org/abs/2305.06586v1)
* 主要机构: SemEval-2023
* 页数: 19
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文介绍了SemEval-2023任务2的发现，该任务是关于细粒度多语言命名实体识别的（MultiCoNER 2）。该任务分为13个轨道，重点研究了在单语和多语情况下，以及嘈杂环境中识别复杂细粒度命名实体（如WRITTENWORK、VEHICLE、MUSICALGRP）的方法。该任务使用了MultiCoNER V2数据集，包括孟加拉语、中文、英语、波斯语、法语、德语、印地语、意大利语、葡萄牙语、西班牙语、瑞典语和乌克兰语等12种语言的220万个实例。MultiCoNER 2是SemEval-2023中最受欢迎的任务之一，吸引了来自47个团队的842个提交，其中34个团队提交了系统论文。结果表明，媒体标题和产品名称等复杂实体类型是最具挑战性的。将外部知识融合到变压器模型中的方法取得了最佳性能，最大的收益在创意作品和群体类别上，即使使用外部知识，这些类别仍然具有挑战性。一些细粒度类别比其他类别更具挑战性，例如SCIENTIST、ARTWORK和PRIVATECORP。我们还观察到，嘈杂的数据对模型性能有显著影响，在嘈杂子集上平均下降了10%。该任务强调了未来研究需要改进在包含复杂实体的嘈杂数据上的NER鲁棒性。
## segmentation
### 标题: Meta-Learners for Few-Shot Weakly-Supervised Medical Image Segmentation
* 文章链接: [http://arxiv.org/abs/2305.06912v1](http://arxiv.org/abs/2305.06912v1)
* 主要机构: None
* 页数: 33
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种通用的元学习框架，用于医学成像领域的少样本弱监督分割。研究比较了不同范式的元学习器在不同稀疏注释放射学任务的少样本图像分割中的适应性。实验考虑了9个元学习器、4个骨干网络和多个目标器官分割任务。研究表明，在领域转移较小的任务中，基于度量的元学习方法实现了更好的分割结果，而一些基于梯度和融合的元学习器对于更大的领域转移具有更好的泛化能力。
### 标题: Convolutional Neural Networks Rarely Learn Shape for Semantic Segmentation
* 文章链接: [http://arxiv.org/abs/2305.06568v1](http://arxiv.org/abs/2305.06568v1)
* 主要机构: DukeUniversity
* 页数: 17
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究旨在探讨卷积神经网络（CNN）是否能够学习形状信息，并提出了一种新的行为度量标准来衡量CNN利用形状信息的程度。通过一系列实验，研究发现，CNN在典型情况下并不会学习形状，而是依赖其他特征来识别目标物体；只有在形状是唯一可用于识别目标的特征时，CNN才能学习形状；此外，对于形状学习，需要足够大的感受野大小相对于目标物体的大小；有限的数据增强可以鼓励形状学习；在存在分布外数据的情况下，学习形状确实是有用的。
### 标题: Undercover Deepfakes: Detecting Fake Segments in Videos
* 文章链接: [http://arxiv.org/abs/2305.06564v1](http://arxiv.org/abs/2305.06564v1)
* 主要机构: None
* 页数: 9
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文介绍了一种新的深度伪造检测方法，能够在帧和视频级别上进行检测。为了测试该方法，作者创建了一个新的基准数据集，其中视频包含真实和伪造的帧序列。该方法利用了Vision Transformer、Scaling and Shifting预训练和Timeseries Transformer来对视频进行时间分段，以便更好地解释可能的深度伪造。在各种深度伪造生成方法上进行的广泛实验表明，该方法在时间分段和经典视频级别预测方面都表现出色。该方法将成为深度伪造的强大工具，可以更好地针对被怀疑为深度伪造的视频部分进行人工监督。
### 标题: Segment and Track Anything
* 文章链接: [http://arxiv.org/abs/2305.06558v1](http://arxiv.org/abs/2305.06558v1)
* 主要机构: ZhejiangUniversity
* 页数: 8
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该报告介绍了一个名为Segment And Track Anything (SAMTrack)的框架，允许用户在视频中精确有效地分割和跟踪任何对象。此外，SAM-Track采用多模态交互方法，使用户能够选择多个视频对象进行跟踪，以满足其特定需求。这些交互方法包括点击、笔画和文本，每种方法都具有独特的优点，可以组合使用。因此，SAM-Track可用于各种领域，从无人机技术、自动驾驶、医学成像、增强现实到生物分析。SAM-Track将Segment Anything Model (SAM)和我们提出的基于AOT的跟踪模型(DeAOT)相结合，以便在视频中进行对象跟踪。此外，SAM-Track还包括Grounding-DINO，使框架支持基于文本的交互。我们已经展示了SAM-Track在DAVIS-2016 Val (92.0%)、DAVIS-2017 Test (79.2%)上的出色能力以及其在各种应用中的实用性。项目页面可在https://github.com/z-x-yang/Segment-and-Track-Anything上找到。
### 标题: WeLayout: WeChat Layout Analysis System for the ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents
* 文章链接: [http://arxiv.org/abs/2305.06553v1](http://arxiv.org/abs/2305.06553v1)
* 主要机构: WeLayout
* 页数: 12
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文介绍了WeLayout，一种新颖的企业文档布局分割系统，代表WeChat布局分析系统。我们的方法利用了DINO和YOLO模型的复杂集合，专门为ICDAR 2023竞赛的鲁棒布局分割开发。我们的方法显着超过了基线，以70.0的mAP在排行榜上获得了顶级位置。为了实现这种性能，我们集中关注了任务的各个方面，例如数据集增强、模型架构、边界框细化和模型集成技术。此外，我们为每个文档类别单独训练数据，以确保更高的平均提交分数。我们还开发了一种单元匹配算法，以进一步提高我们的性能。为了确定我们的模型集成的最佳权重和IoU阈值，我们采用了一种称为树形Parzen估计器的贝叶斯优化算法。我们的方法有效地展示了结合基于查询和无锚点模型以实现企业文档的鲁棒布局分割的好处。
## object detection
### 标题: SalienDet: A Saliency-based Feature Enhancement Algorithm for Object Detection for Autonomous Driving
* 文章链接: [http://arxiv.org/abs/2305.06940v1](http://arxiv.org/abs/2305.06940v1)
* 主要机构: None
* 页数: 13
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 自动驾驶中，目标检测至关重要。未知物体是阻碍自动驾驶车辆超出操作领域的原因之一。该研究提出了一种基于显著性的目标检测算法（SalienDet），用于检测未出现在训练样本集中的物体。SalienDet利用基于显著性的算法增强图像特征以生成目标建议。然后，我们设计了一种数据集重新标记方法，以区分未知物体和所有物体，实现开放世界检测。我们在KITTI、NuScenes和BDD数据集上评估了SalienDet，结果表明它在未知物体检测方面优于现有算法。此外，SalienDet可以轻松适应开放世界检测任务中的增量学习。
### 标题: DeepSTEP -- Deep Learning-Based Spatio-Temporal End-To-End Perception for Autonomous Vehicles
* 文章链接: [http://arxiv.org/abs/2305.06820v1](http://arxiv.org/abs/2305.06820v1)
* 主要机构: DeepSTEP
* 页数: 8
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: DeepSTEP是一种端到端的感知架构，可以从相机、LiDAR和RaDAR等传感器中处理原始数据，并将提取的数据组合在一起。该架构将检测和定位结合在一个管道中，利用自我关注机制来关注最重要的特征。DeepSTEP的设计使其成为自动驾驶车辆感知系统的有前途的解决方案。
### 标题: Towards a Computational Analysis of Suspense: Detecting Dangerous Situations
* 文章链接: [http://arxiv.org/abs/2305.06818v1](http://arxiv.org/abs/2305.06818v1)
* 主要机构: University of Würzburg
* 页数: 8
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 本文探讨了悬疑小说中的危险情境对于建立悬疑的重要性，并引入了一个包含7种危险类型的文本语料库。此外，还对描述角色所经历的恐惧的文本部分进行了标注。实验结果表明，无监督基线方法可以提供有价值的信号，但需要更复杂的方法进行进一步分析。描述危险和恐惧的文本通常依赖于上下文，包括局部和全局上下文。
### 标题: Multi-modal Multi-level Fusion for 3D Single Object Tracking
* 文章链接: [http://arxiv.org/abs/2305.06794v1](http://arxiv.org/abs/2305.06794v1)
* 主要机构: None
* 页数: 8
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 该研究提出了一种多模态多级融合跟踪器（MMF-Track），利用点云的图像纹理和几何特征来跟踪3D目标。该方法通过空间对齐模块（SAM）将RGB图像与点云在3D空间中对齐，然后在特征交互级别上设计了基于双流结构的特征交互模块（FIM），并引入了粗到细交互模块（CFIM）来实现不同尺度的分层特征交互。最后，通过相似度融合模块（SFM）从目标中聚合几何和纹理线索。实验表明，该方法在KITTI上取得了最先进的性能（比以前的多模态方法提高了39％的成功率和42％的精度），在NuScenes上也具有竞争力。
### 标题: Towards a Better Understanding of the Computer Vision Research Community in Africa
* 文章链接: [http://arxiv.org/abs/2305.06773v1](http://arxiv.org/abs/2305.06773v1)
* 主要机构: None
* 页数: 17
* 论文接收情况: None
* 代码链接: [null](null)
* 中文总结: 计算机视觉是一个广泛的研究领域，包括不同的任务（例如，物体检测、语义分割、3D重建）。尽管计算机视觉在非洲社区的各种应用中具有相关性，但计算机视觉研究在非洲大陆上尚未得到充分探索，过去10年中仅占顶级出版物的0.06％。本文旨在通过对非洲计算机视觉出版物的实证分析，更好地了解非洲的计算机视觉研究，并提供指导是否存在研究公平性的指针。总之，我们的分析揭示了非洲研究人员是非洲研究的关键贡献者，但存在多个障碍在顶级出版物上发表文章，而大陆上目前发表的主题趋势可能不一定反映社区的需求。
### 标题: PVT-SSD: Single-Stage 3D Object Detector with Point-Voxel Transformer
* 文章链接: [http://arxiv.org/abs/2305.06621v1](http://arxiv.org/abs/2305.06621v1)
* 主要机构: ZhejiangUnive.
* 页数: 12
* 论文接收情况: CVPR 2023
* 代码链接: [null](null)
* 中文总结: 本文提出了一种新的单阶段三维检测器Point-Voxel Transformer for single-stage 3D detection (PVT-SSD)，它利用点云和体素表示的优势。首先使用基于体素的稀疏卷积进行有效的特征编码，然后提出了Point-Voxel Transformer (PVT)模块，从体素中以廉价的方式获取长距离上下文，同时从点中获得准确的位置。将两种不同的表示关联起来的关键是我们引入的输入依赖的查询初始化模块，它可以有效地生成参考点和内容查询。然后，PVT将参考点周围的长距离上下文和局部几何信息自适应地融合到内容查询中。此外，为了快速找到参考点的邻近点，我们设计了虚拟范围图像模块，将原生范围图像推广到多传感器和多帧。在几个自动驾驶基准测试中的实验验证了所提出方法的有效性和效率。代码将在https://github.com/Nightmare-n/PVT-SSD上提供。
